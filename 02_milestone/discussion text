The notebook to submit this week should at least include:

Discussion about the imbalanced nature of the data and how you want to address it
Description of your data
What does your choice of Y look like?
Which features do you choose for X and why?
How do you sample your data, how many samples, and why?

Proposal
1. Primary research question: genre prediction
a. How well do poster images predict three genres (romance, horror and sci-fi)?
b. How well do the text of movie titles and descriptions predict these genres?

Data setup (Y):
In Milestone 1 we found that the movie databases contain around 20 genre classes, some of which are much more common than others; that many movies are assigned multiple genre classes; and that a movie's genre assignments can vary across databases. For this project, however, we will sample only movies assigned to one of these three classes (excluding movies assigned to more than one of the three, but including movies which have also been assigned additional genres). Each genre will constitute exactly 1/3 of our sample. These movies are selected based on popularity, based on our assumption that more-popular movies are more representative of their genres, and balanced by year from 1960-present, for reasons of interest in part 2 below. The full dataset is [1500?] movies with [20%?] reserved for testing. The size is based on (i) the maximum we believe is computationally feasible for question 1a, and (ii) our a priori belief that less-popular movies from within each genre may be less "pure" representations of the genre. We will account for genre in assigning movies to the testing set, yielding perfectly balanced training and testing sets that will make it easier to detect trends in classifier performance. [any thoughts on the proportion that should be assigned to testing?] 

Comments:
This sampling method eliminates the imbalance problem in the broader database, while allowing us to answer the focused research question of how well CNNs can learn to distinguish among these genres. The particular genres were chosen using the correlation matrix we produced in Milestone 1, finding little overlap among these genres, and based on their sociological relevance. Choosing three classes allows us to consider relative distances among the classes and compare predictor performance in distinguishing among them--e.g., our hypothesis is that among these classes, sci-fi and horror are comparatively closer to each other than to romance, and will therefore be slightly harder to predict accurately.

Data setup (X):
We are most interested in movie posters and movie titles & descriptions as predictors. We propose to optimize predictions using primarily (or exclusively) these predictors, rather than attempting to optimize predictions using whatever additional predictor data we might be able to access. Our initial thinking is to run models using these predictors separately (i.e. (a) poster vs. genre and (b) description vs. genre).  

Comments:
We prefer this approach because it will allow us to consider, in more depth, the relationship between each predictor and the genre classification. These features are all constructed with the intention of conveying information about the movie to prospective viewers (as opposed to, for example, language or director). We expect these features have a true relationship with genre, allowing the possibility of good classification accuracy--our submission this week includes an exploratory modeling exercise to predict horror vs. romance using PCA/SVM with test set accuracy of 87%, demonstrating the feasibility of the general approach. We also believe that the nature of this relationship represents an interesting research question: i.e. how effectively do title/descriptions and posters convey genre, and how well can algorithms learn to detect this relationship? Thus, while including additional features might (or might not) improve classification accuracy, they are not as relevant to the research questions that interest us most. 

2. Secondary research question: poster age identification
--can CNNs predict a movie's release decade based on its poster?

Brief discussion:
Time permitting, we would like to set up a distinct classification task in which we sample from one genre (most likely sci-fi) and train a CNN to predict decade (e.g. 1960s/70s/80s/90s/00s/10s). We think this task may be of greatest substantive interest for science fiction movies, where we believe posters are representative of the era's visualizations of alternative realities. Have these changed over times in ways that a CNN can learn to identify? A priori we think color combinations may be especially predictive of decade. 





