{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 396 images belonging to 3 classes.\n",
      "Found 264 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 185, 278\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_2_model.h5'\n",
    "train_data_dir = 'Posters 660/Train'\n",
    "validation_data_dir = 'Posters 660/Validation'\n",
    "nb_train_samples = 396\n",
    "nb_validation_samples = 264\n",
    "epochs = 50\n",
    "batch_size = 36 # difference in this version: train the VGG using a larger batch size\n",
    "\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_2_train.npy', 'w'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('bottleneck_features_2_validation.npy', 'w'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 396 samples, validate on 264 samples\n",
      "Epoch 1/100\n",
      "396/396 [==============================] - 3s - loss: 0.7249 - acc: 0.5051 - val_loss: 0.6892 - val_acc: 0.5568\n",
      "Epoch 2/100\n",
      "396/396 [==============================] - 0s - loss: 0.7244 - acc: 0.4874 - val_loss: 0.6832 - val_acc: 0.5720\n",
      "Epoch 3/100\n",
      "396/396 [==============================] - 0s - loss: 0.6905 - acc: 0.5631 - val_loss: 0.6801 - val_acc: 0.5720\n",
      "Epoch 4/100\n",
      "396/396 [==============================] - 0s - loss: 0.6915 - acc: 0.5505 - val_loss: 0.6745 - val_acc: 0.6250\n",
      "Epoch 5/100\n",
      "396/396 [==============================] - 0s - loss: 0.7064 - acc: 0.5404 - val_loss: 0.6710 - val_acc: 0.6515\n",
      "Epoch 6/100\n",
      "396/396 [==============================] - 0s - loss: 0.6698 - acc: 0.6086 - val_loss: 0.6671 - val_acc: 0.6515\n",
      "Epoch 7/100\n",
      "396/396 [==============================] - 0s - loss: 0.6645 - acc: 0.5859 - val_loss: 0.6639 - val_acc: 0.6667\n",
      "Epoch 8/100\n",
      "396/396 [==============================] - 0s - loss: 0.6627 - acc: 0.6061 - val_loss: 0.6605 - val_acc: 0.6629\n",
      "Epoch 9/100\n",
      "396/396 [==============================] - 0s - loss: 0.6585 - acc: 0.6187 - val_loss: 0.6565 - val_acc: 0.6818\n",
      "Epoch 10/100\n",
      "396/396 [==============================] - 0s - loss: 0.6378 - acc: 0.6187 - val_loss: 0.6537 - val_acc: 0.6667\n",
      "Epoch 11/100\n",
      "396/396 [==============================] - 0s - loss: 0.6569 - acc: 0.6162 - val_loss: 0.6507 - val_acc: 0.6667\n",
      "Epoch 12/100\n",
      "396/396 [==============================] - 0s - loss: 0.6551 - acc: 0.6086 - val_loss: 0.6490 - val_acc: 0.6705\n",
      "Epoch 13/100\n",
      "396/396 [==============================] - 0s - loss: 0.6249 - acc: 0.6616 - val_loss: 0.6474 - val_acc: 0.6742\n",
      "Epoch 14/100\n",
      "396/396 [==============================] - 0s - loss: 0.6382 - acc: 0.6566 - val_loss: 0.6442 - val_acc: 0.6818\n",
      "Epoch 15/100\n",
      "396/396 [==============================] - 0s - loss: 0.6252 - acc: 0.6566 - val_loss: 0.6412 - val_acc: 0.6818\n",
      "Epoch 16/100\n",
      "396/396 [==============================] - 0s - loss: 0.6216 - acc: 0.6389 - val_loss: 0.6382 - val_acc: 0.6780\n",
      "Epoch 17/100\n",
      "396/396 [==============================] - 0s - loss: 0.6199 - acc: 0.6894 - val_loss: 0.6358 - val_acc: 0.6629\n",
      "Epoch 18/100\n",
      "396/396 [==============================] - 0s - loss: 0.6064 - acc: 0.6995 - val_loss: 0.6323 - val_acc: 0.6856\n",
      "Epoch 19/100\n",
      "396/396 [==============================] - 0s - loss: 0.6005 - acc: 0.7096 - val_loss: 0.6313 - val_acc: 0.6705\n",
      "Epoch 20/100\n",
      "396/396 [==============================] - 0s - loss: 0.6168 - acc: 0.6667 - val_loss: 0.6304 - val_acc: 0.6932\n",
      "Epoch 21/100\n",
      "396/396 [==============================] - 0s - loss: 0.6004 - acc: 0.6944 - val_loss: 0.6305 - val_acc: 0.6742\n",
      "Epoch 22/100\n",
      "396/396 [==============================] - 0s - loss: 0.5988 - acc: 0.6995 - val_loss: 0.6321 - val_acc: 0.6591\n",
      "Epoch 23/100\n",
      "396/396 [==============================] - 0s - loss: 0.5969 - acc: 0.7020 - val_loss: 0.6231 - val_acc: 0.6894\n",
      "Epoch 24/100\n",
      "396/396 [==============================] - 0s - loss: 0.5905 - acc: 0.7121 - val_loss: 0.6207 - val_acc: 0.6932\n",
      "Epoch 25/100\n",
      "396/396 [==============================] - 0s - loss: 0.5861 - acc: 0.7172 - val_loss: 0.6181 - val_acc: 0.6856\n",
      "Epoch 26/100\n",
      "396/396 [==============================] - 0s - loss: 0.5801 - acc: 0.6919 - val_loss: 0.6165 - val_acc: 0.7008\n",
      "Epoch 27/100\n",
      "396/396 [==============================] - 0s - loss: 0.5659 - acc: 0.7298 - val_loss: 0.6146 - val_acc: 0.7083\n",
      "Epoch 28/100\n",
      "396/396 [==============================] - 0s - loss: 0.5634 - acc: 0.7551 - val_loss: 0.6117 - val_acc: 0.7008\n",
      "Epoch 29/100\n",
      "396/396 [==============================] - 0s - loss: 0.5683 - acc: 0.7652 - val_loss: 0.6116 - val_acc: 0.7045\n",
      "Epoch 30/100\n",
      "396/396 [==============================] - 0s - loss: 0.5520 - acc: 0.7551 - val_loss: 0.6083 - val_acc: 0.6970\n",
      "Epoch 31/100\n",
      "396/396 [==============================] - 0s - loss: 0.5581 - acc: 0.7475 - val_loss: 0.6111 - val_acc: 0.6742\n",
      "Epoch 32/100\n",
      "396/396 [==============================] - 0s - loss: 0.5619 - acc: 0.7247 - val_loss: 0.6050 - val_acc: 0.6894\n",
      "Epoch 33/100\n",
      "396/396 [==============================] - 0s - loss: 0.5708 - acc: 0.7348 - val_loss: 0.6045 - val_acc: 0.6970\n",
      "Epoch 34/100\n",
      "396/396 [==============================] - 0s - loss: 0.5379 - acc: 0.7778 - val_loss: 0.6078 - val_acc: 0.6856\n",
      "Epoch 35/100\n",
      "396/396 [==============================] - 0s - loss: 0.5354 - acc: 0.7702 - val_loss: 0.6001 - val_acc: 0.7008\n",
      "Epoch 36/100\n",
      "396/396 [==============================] - 0s - loss: 0.5260 - acc: 0.7854 - val_loss: 0.5986 - val_acc: 0.6894\n",
      "Epoch 37/100\n",
      "396/396 [==============================] - 0s - loss: 0.5297 - acc: 0.7854 - val_loss: 0.5984 - val_acc: 0.7121\n",
      "Epoch 38/100\n",
      "396/396 [==============================] - 0s - loss: 0.5154 - acc: 0.8030 - val_loss: 0.5948 - val_acc: 0.7083\n",
      "Epoch 39/100\n",
      "396/396 [==============================] - 0s - loss: 0.5298 - acc: 0.7727 - val_loss: 0.5938 - val_acc: 0.7045\n",
      "Epoch 40/100\n",
      "396/396 [==============================] - 0s - loss: 0.5233 - acc: 0.7854 - val_loss: 0.5925 - val_acc: 0.7083\n",
      "Epoch 41/100\n",
      "396/396 [==============================] - 0s - loss: 0.5171 - acc: 0.7955 - val_loss: 0.6018 - val_acc: 0.6705\n",
      "Epoch 42/100\n",
      "396/396 [==============================] - 0s - loss: 0.5002 - acc: 0.8131 - val_loss: 0.5916 - val_acc: 0.7121\n",
      "Epoch 43/100\n",
      "396/396 [==============================] - 0s - loss: 0.5209 - acc: 0.7753 - val_loss: 0.5905 - val_acc: 0.7008\n",
      "Epoch 44/100\n",
      "396/396 [==============================] - 0s - loss: 0.5127 - acc: 0.7929 - val_loss: 0.5878 - val_acc: 0.7121\n",
      "Epoch 45/100\n",
      "396/396 [==============================] - 1s - loss: 0.5021 - acc: 0.7879 - val_loss: 0.5865 - val_acc: 0.7008\n",
      "Epoch 46/100\n",
      "396/396 [==============================] - 0s - loss: 0.4864 - acc: 0.8232 - val_loss: 0.5840 - val_acc: 0.6932\n",
      "Epoch 47/100\n",
      "396/396 [==============================] - 1s - loss: 0.4700 - acc: 0.8232 - val_loss: 0.5826 - val_acc: 0.7045\n",
      "Epoch 48/100\n",
      "396/396 [==============================] - 0s - loss: 0.4821 - acc: 0.8258 - val_loss: 0.5818 - val_acc: 0.7083\n",
      "Epoch 49/100\n",
      "396/396 [==============================] - 0s - loss: 0.4696 - acc: 0.8359 - val_loss: 0.5808 - val_acc: 0.7083\n",
      "Epoch 50/100\n",
      "396/396 [==============================] - 0s - loss: 0.4811 - acc: 0.8182 - val_loss: 0.5788 - val_acc: 0.7121\n",
      "Epoch 51/100\n",
      "396/396 [==============================] - 0s - loss: 0.4607 - acc: 0.8232 - val_loss: 0.5780 - val_acc: 0.7045\n",
      "Epoch 52/100\n",
      "396/396 [==============================] - 0s - loss: 0.4749 - acc: 0.8030 - val_loss: 0.5760 - val_acc: 0.7045\n",
      "Epoch 53/100\n",
      "396/396 [==============================] - 0s - loss: 0.4673 - acc: 0.8207 - val_loss: 0.5763 - val_acc: 0.7197\n",
      "Epoch 54/100\n",
      "396/396 [==============================] - 0s - loss: 0.4553 - acc: 0.8258 - val_loss: 0.5754 - val_acc: 0.7083\n",
      "Epoch 55/100\n",
      "396/396 [==============================] - 0s - loss: 0.4626 - acc: 0.8131 - val_loss: 0.5735 - val_acc: 0.7197\n",
      "Epoch 56/100\n",
      "396/396 [==============================] - 0s - loss: 0.4424 - acc: 0.8333 - val_loss: 0.5749 - val_acc: 0.7083\n",
      "Epoch 57/100\n",
      "396/396 [==============================] - 0s - loss: 0.4507 - acc: 0.8535 - val_loss: 0.5715 - val_acc: 0.7197\n",
      "Epoch 58/100\n",
      "396/396 [==============================] - 1s - loss: 0.4424 - acc: 0.8535 - val_loss: 0.5708 - val_acc: 0.7121\n",
      "Epoch 59/100\n",
      "396/396 [==============================] - 0s - loss: 0.4297 - acc: 0.8611 - val_loss: 0.5702 - val_acc: 0.7121\n",
      "Epoch 60/100\n",
      "396/396 [==============================] - 0s - loss: 0.4521 - acc: 0.8333 - val_loss: 0.5694 - val_acc: 0.7197\n",
      "Epoch 61/100\n",
      "396/396 [==============================] - 0s - loss: 0.4392 - acc: 0.8384 - val_loss: 0.5699 - val_acc: 0.7197\n",
      "Epoch 62/100\n",
      "396/396 [==============================] - 0s - loss: 0.4345 - acc: 0.8460 - val_loss: 0.5690 - val_acc: 0.7235\n",
      "Epoch 63/100\n",
      "396/396 [==============================] - 0s - loss: 0.4356 - acc: 0.8434 - val_loss: 0.5674 - val_acc: 0.7197\n",
      "Epoch 64/100\n",
      "396/396 [==============================] - 1s - loss: 0.4134 - acc: 0.8687 - val_loss: 0.5670 - val_acc: 0.7197\n",
      "Epoch 65/100\n",
      "396/396 [==============================] - 0s - loss: 0.4313 - acc: 0.8535 - val_loss: 0.5757 - val_acc: 0.6970\n",
      "Epoch 66/100\n",
      "396/396 [==============================] - 0s - loss: 0.4176 - acc: 0.8662 - val_loss: 0.5668 - val_acc: 0.7197\n",
      "Epoch 67/100\n",
      "396/396 [==============================] - 0s - loss: 0.4244 - acc: 0.8510 - val_loss: 0.5666 - val_acc: 0.7083\n",
      "Epoch 68/100\n",
      "396/396 [==============================] - 0s - loss: 0.4123 - acc: 0.8662 - val_loss: 0.5651 - val_acc: 0.7197\n",
      "Epoch 69/100\n",
      "396/396 [==============================] - 0s - loss: 0.4116 - acc: 0.8510 - val_loss: 0.5684 - val_acc: 0.7045\n",
      "Epoch 70/100\n",
      "396/396 [==============================] - 0s - loss: 0.4029 - acc: 0.8687 - val_loss: 0.5658 - val_acc: 0.7045\n",
      "Epoch 71/100\n",
      "396/396 [==============================] - 0s - loss: 0.4035 - acc: 0.8611 - val_loss: 0.5708 - val_acc: 0.6970\n",
      "Epoch 72/100\n",
      "396/396 [==============================] - 0s - loss: 0.3930 - acc: 0.8813 - val_loss: 0.5643 - val_acc: 0.7235\n",
      "Epoch 73/100\n",
      "396/396 [==============================] - 0s - loss: 0.4030 - acc: 0.8662 - val_loss: 0.5767 - val_acc: 0.6818\n",
      "Epoch 74/100\n",
      "396/396 [==============================] - 0s - loss: 0.4012 - acc: 0.8687 - val_loss: 0.5699 - val_acc: 0.6932\n",
      "Epoch 75/100\n",
      "396/396 [==============================] - 0s - loss: 0.3974 - acc: 0.8712 - val_loss: 0.5638 - val_acc: 0.7311\n",
      "Epoch 76/100\n",
      "396/396 [==============================] - 0s - loss: 0.3863 - acc: 0.8788 - val_loss: 0.5696 - val_acc: 0.6970\n",
      "Epoch 77/100\n",
      "396/396 [==============================] - 1s - loss: 0.3827 - acc: 0.8788 - val_loss: 0.5696 - val_acc: 0.6970\n",
      "Epoch 78/100\n",
      "396/396 [==============================] - 1s - loss: 0.3883 - acc: 0.8788 - val_loss: 0.5634 - val_acc: 0.7235\n",
      "Epoch 79/100\n",
      "396/396 [==============================] - 0s - loss: 0.3905 - acc: 0.8889 - val_loss: 0.5657 - val_acc: 0.7045\n",
      "Epoch 80/100\n",
      "396/396 [==============================] - 0s - loss: 0.3772 - acc: 0.8788 - val_loss: 0.5631 - val_acc: 0.7235\n",
      "Epoch 81/100\n",
      "396/396 [==============================] - 0s - loss: 0.3823 - acc: 0.8636 - val_loss: 0.5650 - val_acc: 0.7121\n",
      "Epoch 82/100\n",
      "396/396 [==============================] - 0s - loss: 0.3521 - acc: 0.9066 - val_loss: 0.5643 - val_acc: 0.7121\n",
      "Epoch 83/100\n",
      "396/396 [==============================] - 0s - loss: 0.3626 - acc: 0.8763 - val_loss: 0.5635 - val_acc: 0.7159\n",
      "Epoch 84/100\n",
      "396/396 [==============================] - 0s - loss: 0.3660 - acc: 0.8763 - val_loss: 0.5636 - val_acc: 0.7235\n",
      "Epoch 85/100\n",
      "396/396 [==============================] - 0s - loss: 0.3540 - acc: 0.8939 - val_loss: 0.5629 - val_acc: 0.7311\n",
      "Epoch 86/100\n",
      "396/396 [==============================] - 0s - loss: 0.3666 - acc: 0.8788 - val_loss: 0.5706 - val_acc: 0.7008\n",
      "Epoch 87/100\n",
      "396/396 [==============================] - 0s - loss: 0.3526 - acc: 0.8813 - val_loss: 0.5652 - val_acc: 0.7159\n",
      "Epoch 88/100\n",
      "396/396 [==============================] - 0s - loss: 0.3507 - acc: 0.8914 - val_loss: 0.5657 - val_acc: 0.7083\n",
      "Epoch 89/100\n",
      "396/396 [==============================] - 0s - loss: 0.3374 - acc: 0.8939 - val_loss: 0.5774 - val_acc: 0.6894\n",
      "Epoch 90/100\n",
      "396/396 [==============================] - 0s - loss: 0.3492 - acc: 0.9091 - val_loss: 0.5732 - val_acc: 0.6932\n",
      "Epoch 91/100\n",
      "396/396 [==============================] - 0s - loss: 0.3298 - acc: 0.8965 - val_loss: 0.5649 - val_acc: 0.7121\n",
      "Epoch 92/100\n",
      "396/396 [==============================] - 0s - loss: 0.3492 - acc: 0.8939 - val_loss: 0.5720 - val_acc: 0.6970\n",
      "Epoch 93/100\n",
      "396/396 [==============================] - 0s - loss: 0.3261 - acc: 0.9091 - val_loss: 0.5718 - val_acc: 0.7008\n",
      "Epoch 94/100\n",
      "396/396 [==============================] - 0s - loss: 0.3358 - acc: 0.9040 - val_loss: 0.5648 - val_acc: 0.7273\n",
      "Epoch 95/100\n",
      "396/396 [==============================] - 0s - loss: 0.3408 - acc: 0.9066 - val_loss: 0.5657 - val_acc: 0.7159\n",
      "Epoch 96/100\n",
      "396/396 [==============================] - 0s - loss: 0.3318 - acc: 0.8990 - val_loss: 0.5649 - val_acc: 0.7273\n",
      "Epoch 97/100\n",
      "396/396 [==============================] - 0s - loss: 0.3362 - acc: 0.8712 - val_loss: 0.5911 - val_acc: 0.6629\n",
      "Epoch 98/100\n",
      "396/396 [==============================] - 1s - loss: 0.3253 - acc: 0.9116 - val_loss: 0.5688 - val_acc: 0.7197\n",
      "Epoch 99/100\n",
      "396/396 [==============================] - 0s - loss: 0.3215 - acc: 0.8965 - val_loss: 0.5768 - val_acc: 0.6932\n",
      "Epoch 100/100\n",
      "396/396 [==============================] - 0s - loss: 0.3122 - acc: 0.9141 - val_loss: 0.5685 - val_acc: 0.7008\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'Posters 660/Train'\n",
    "validation_data_dir = 'Posters 660/Validation'\n",
    "nb_train_samples = 396\n",
    "nb_validation_samples = 264\n",
    "epochs = 100\n",
    "batch_size = 36 \n",
    "\n",
    "sgd = SGD(lr=0.001, decay=0.00001) # lower learning rate\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples / 2) + [1] * (nb_train_samples / 2))\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples / 2) + [1] * (nb_validation_samples / 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "#add more layers, eliminate dropout\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu')) \n",
    "    model.add(Dense(512, activation='relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 396 samples, validate on 264 samples\n",
      "Epoch 1/100\n",
      "396/396 [==============================] - 2s - loss: 0.7264 - acc: 0.5051 - val_loss: 0.6945 - val_acc: 0.5038\n",
      "Epoch 2/100\n",
      "396/396 [==============================] - 0s - loss: 0.6980 - acc: 0.5631 - val_loss: 0.6908 - val_acc: 0.5227\n",
      "Epoch 3/100\n",
      "396/396 [==============================] - 0s - loss: 0.7030 - acc: 0.5202 - val_loss: 0.6876 - val_acc: 0.5720\n",
      "Epoch 4/100\n",
      "396/396 [==============================] - 0s - loss: 0.6778 - acc: 0.5480 - val_loss: 0.6861 - val_acc: 0.5606\n",
      "Epoch 5/100\n",
      "396/396 [==============================] - 0s - loss: 0.6841 - acc: 0.5859 - val_loss: 0.6816 - val_acc: 0.5795\n",
      "Epoch 6/100\n",
      "396/396 [==============================] - 0s - loss: 0.6657 - acc: 0.5859 - val_loss: 0.6798 - val_acc: 0.5833\n",
      "Epoch 7/100\n",
      "396/396 [==============================] - 0s - loss: 0.6657 - acc: 0.5934 - val_loss: 0.6768 - val_acc: 0.5947\n",
      "Epoch 8/100\n",
      "396/396 [==============================] - 0s - loss: 0.6595 - acc: 0.6237 - val_loss: 0.6748 - val_acc: 0.5720\n",
      "Epoch 9/100\n",
      "396/396 [==============================] - 0s - loss: 0.6815 - acc: 0.5631 - val_loss: 0.6724 - val_acc: 0.5947\n",
      "Epoch 10/100\n",
      "396/396 [==============================] - 0s - loss: 0.6551 - acc: 0.5859 - val_loss: 0.6716 - val_acc: 0.6250\n",
      "Epoch 11/100\n",
      "396/396 [==============================] - 0s - loss: 0.6454 - acc: 0.6465 - val_loss: 0.6701 - val_acc: 0.6023\n",
      "Epoch 12/100\n",
      "396/396 [==============================] - 0s - loss: 0.6308 - acc: 0.6591 - val_loss: 0.6683 - val_acc: 0.5985\n",
      "Epoch 13/100\n",
      "396/396 [==============================] - 0s - loss: 0.6485 - acc: 0.6338 - val_loss: 0.6650 - val_acc: 0.6061\n",
      "Epoch 14/100\n",
      "396/396 [==============================] - 0s - loss: 0.6204 - acc: 0.6843 - val_loss: 0.6634 - val_acc: 0.6098\n",
      "Epoch 15/100\n",
      "396/396 [==============================] - 0s - loss: 0.6347 - acc: 0.6616 - val_loss: 0.6619 - val_acc: 0.6136\n",
      "Epoch 16/100\n",
      "396/396 [==============================] - 0s - loss: 0.6330 - acc: 0.6338 - val_loss: 0.6601 - val_acc: 0.6212\n",
      "Epoch 17/100\n",
      "396/396 [==============================] - 0s - loss: 0.6301 - acc: 0.6793 - val_loss: 0.6578 - val_acc: 0.6326\n",
      "Epoch 18/100\n",
      "396/396 [==============================] - 0s - loss: 0.6306 - acc: 0.6616 - val_loss: 0.6560 - val_acc: 0.6402\n",
      "Epoch 19/100\n",
      "396/396 [==============================] - 0s - loss: 0.6091 - acc: 0.7071 - val_loss: 0.6524 - val_acc: 0.6477\n",
      "Epoch 20/100\n",
      "396/396 [==============================] - 0s - loss: 0.6059 - acc: 0.6970 - val_loss: 0.6519 - val_acc: 0.6591\n",
      "Epoch 21/100\n",
      "396/396 [==============================] - 1s - loss: 0.5995 - acc: 0.7071 - val_loss: 0.6470 - val_acc: 0.6515\n",
      "Epoch 22/100\n",
      "396/396 [==============================] - 1s - loss: 0.6036 - acc: 0.7020 - val_loss: 0.6448 - val_acc: 0.6477\n",
      "Epoch 23/100\n",
      "396/396 [==============================] - 0s - loss: 0.5893 - acc: 0.7626 - val_loss: 0.6426 - val_acc: 0.6515\n",
      "Epoch 24/100\n",
      "396/396 [==============================] - 0s - loss: 0.6061 - acc: 0.7247 - val_loss: 0.6422 - val_acc: 0.6705\n",
      "Epoch 25/100\n",
      "396/396 [==============================] - 0s - loss: 0.6049 - acc: 0.6894 - val_loss: 0.6400 - val_acc: 0.6515\n",
      "Epoch 26/100\n",
      "396/396 [==============================] - 0s - loss: 0.5837 - acc: 0.7298 - val_loss: 0.6392 - val_acc: 0.6667\n",
      "Epoch 27/100\n",
      "396/396 [==============================] - 0s - loss: 0.6065 - acc: 0.6742 - val_loss: 0.6362 - val_acc: 0.6515\n",
      "Epoch 28/100\n",
      "396/396 [==============================] - 0s - loss: 0.5673 - acc: 0.7753 - val_loss: 0.6344 - val_acc: 0.6477\n",
      "Epoch 29/100\n",
      "396/396 [==============================] - 0s - loss: 0.5855 - acc: 0.7045 - val_loss: 0.6322 - val_acc: 0.6591\n",
      "Epoch 30/100\n",
      "396/396 [==============================] - 0s - loss: 0.5834 - acc: 0.7273 - val_loss: 0.6303 - val_acc: 0.6629\n",
      "Epoch 31/100\n",
      "396/396 [==============================] - 0s - loss: 0.5558 - acc: 0.7828 - val_loss: 0.6285 - val_acc: 0.6553\n",
      "Epoch 32/100\n",
      "396/396 [==============================] - 0s - loss: 0.5664 - acc: 0.7273 - val_loss: 0.6282 - val_acc: 0.6515\n",
      "Epoch 33/100\n",
      "396/396 [==============================] - 0s - loss: 0.5551 - acc: 0.7828 - val_loss: 0.6249 - val_acc: 0.6629\n",
      "Epoch 34/100\n",
      "396/396 [==============================] - 0s - loss: 0.5665 - acc: 0.7273 - val_loss: 0.6232 - val_acc: 0.6742\n",
      "Epoch 35/100\n",
      "396/396 [==============================] - 0s - loss: 0.5492 - acc: 0.7576 - val_loss: 0.6254 - val_acc: 0.6402\n",
      "Epoch 36/100\n",
      "396/396 [==============================] - 0s - loss: 0.5516 - acc: 0.7525 - val_loss: 0.6212 - val_acc: 0.6629\n",
      "Epoch 37/100\n",
      "396/396 [==============================] - 0s - loss: 0.5524 - acc: 0.7652 - val_loss: 0.6202 - val_acc: 0.6402\n",
      "Epoch 38/100\n",
      "396/396 [==============================] - 0s - loss: 0.5467 - acc: 0.7551 - val_loss: 0.6177 - val_acc: 0.6515\n",
      "Epoch 39/100\n",
      "396/396 [==============================] - 0s - loss: 0.5301 - acc: 0.7803 - val_loss: 0.6158 - val_acc: 0.6591\n",
      "Epoch 40/100\n",
      "396/396 [==============================] - 0s - loss: 0.5338 - acc: 0.7803 - val_loss: 0.6168 - val_acc: 0.6402\n",
      "Epoch 41/100\n",
      "396/396 [==============================] - 0s - loss: 0.5302 - acc: 0.7803 - val_loss: 0.6162 - val_acc: 0.6780\n",
      "Epoch 42/100\n",
      "396/396 [==============================] - 0s - loss: 0.5364 - acc: 0.7652 - val_loss: 0.6148 - val_acc: 0.6515\n",
      "Epoch 43/100\n",
      "396/396 [==============================] - 0s - loss: 0.5217 - acc: 0.7828 - val_loss: 0.6116 - val_acc: 0.6477\n",
      "Epoch 44/100\n",
      "396/396 [==============================] - 0s - loss: 0.5119 - acc: 0.7904 - val_loss: 0.6079 - val_acc: 0.6705\n",
      "Epoch 45/100\n",
      "396/396 [==============================] - 0s - loss: 0.5206 - acc: 0.7828 - val_loss: 0.6076 - val_acc: 0.6591\n",
      "Epoch 46/100\n",
      "396/396 [==============================] - 0s - loss: 0.4979 - acc: 0.8359 - val_loss: 0.6060 - val_acc: 0.6705\n",
      "Epoch 47/100\n",
      "396/396 [==============================] - 0s - loss: 0.5116 - acc: 0.7854 - val_loss: 0.6101 - val_acc: 0.7008\n",
      "Epoch 48/100\n",
      "396/396 [==============================] - 0s - loss: 0.5115 - acc: 0.8030 - val_loss: 0.6056 - val_acc: 0.6742\n",
      "Epoch 49/100\n",
      "396/396 [==============================] - 0s - loss: 0.5026 - acc: 0.7955 - val_loss: 0.6012 - val_acc: 0.6705\n",
      "Epoch 50/100\n",
      "396/396 [==============================] - 0s - loss: 0.4830 - acc: 0.8106 - val_loss: 0.6002 - val_acc: 0.6818\n",
      "Epoch 51/100\n",
      "396/396 [==============================] - 0s - loss: 0.5038 - acc: 0.8030 - val_loss: 0.5989 - val_acc: 0.6894\n",
      "Epoch 52/100\n",
      "396/396 [==============================] - 0s - loss: 0.5050 - acc: 0.7929 - val_loss: 0.5998 - val_acc: 0.6629\n",
      "Epoch 53/100\n",
      "396/396 [==============================] - 0s - loss: 0.4976 - acc: 0.7980 - val_loss: 0.5969 - val_acc: 0.6894\n",
      "Epoch 54/100\n",
      "396/396 [==============================] - 0s - loss: 0.4781 - acc: 0.8207 - val_loss: 0.6003 - val_acc: 0.6818\n",
      "Epoch 55/100\n",
      "396/396 [==============================] - 0s - loss: 0.4776 - acc: 0.8081 - val_loss: 0.5954 - val_acc: 0.6780\n",
      "Epoch 56/100\n",
      "396/396 [==============================] - 0s - loss: 0.4736 - acc: 0.8157 - val_loss: 0.5944 - val_acc: 0.6970\n",
      "Epoch 57/100\n",
      "396/396 [==============================] - 0s - loss: 0.4941 - acc: 0.7955 - val_loss: 0.5933 - val_acc: 0.6780\n",
      "Epoch 58/100\n",
      "396/396 [==============================] - 0s - loss: 0.4732 - acc: 0.8409 - val_loss: 0.5956 - val_acc: 0.6856\n",
      "Epoch 59/100\n",
      "396/396 [==============================] - 0s - loss: 0.4514 - acc: 0.8258 - val_loss: 0.5909 - val_acc: 0.6742\n",
      "Epoch 60/100\n",
      "396/396 [==============================] - 0s - loss: 0.4591 - acc: 0.8409 - val_loss: 0.5930 - val_acc: 0.6742\n",
      "Epoch 61/100\n",
      "396/396 [==============================] - 0s - loss: 0.4659 - acc: 0.8308 - val_loss: 0.5897 - val_acc: 0.6856\n",
      "Epoch 62/100\n",
      "396/396 [==============================] - 0s - loss: 0.4588 - acc: 0.8359 - val_loss: 0.5893 - val_acc: 0.6818\n",
      "Epoch 63/100\n",
      "396/396 [==============================] - 0s - loss: 0.4498 - acc: 0.8359 - val_loss: 0.5893 - val_acc: 0.6856\n",
      "Epoch 64/100\n",
      "396/396 [==============================] - 0s - loss: 0.4556 - acc: 0.8232 - val_loss: 0.5884 - val_acc: 0.6667\n",
      "Epoch 65/100\n",
      "396/396 [==============================] - 0s - loss: 0.4469 - acc: 0.8434 - val_loss: 0.5884 - val_acc: 0.6818\n",
      "Epoch 66/100\n",
      "396/396 [==============================] - 0s - loss: 0.4370 - acc: 0.8535 - val_loss: 0.5880 - val_acc: 0.6818\n",
      "Epoch 67/100\n",
      "396/396 [==============================] - 0s - loss: 0.4481 - acc: 0.8359 - val_loss: 0.5873 - val_acc: 0.6818\n",
      "Epoch 68/100\n",
      "396/396 [==============================] - 0s - loss: 0.4353 - acc: 0.8283 - val_loss: 0.5885 - val_acc: 0.6780\n",
      "Epoch 69/100\n",
      "396/396 [==============================] - 0s - loss: 0.4355 - acc: 0.8434 - val_loss: 0.5879 - val_acc: 0.6780\n",
      "Epoch 70/100\n",
      "396/396 [==============================] - 0s - loss: 0.4197 - acc: 0.8636 - val_loss: 0.5844 - val_acc: 0.6856\n",
      "Epoch 71/100\n",
      "396/396 [==============================] - 0s - loss: 0.4342 - acc: 0.8283 - val_loss: 0.5856 - val_acc: 0.6818\n",
      "Epoch 72/100\n",
      "396/396 [==============================] - 0s - loss: 0.4211 - acc: 0.8687 - val_loss: 0.5858 - val_acc: 0.6742\n",
      "Epoch 73/100\n",
      "396/396 [==============================] - 0s - loss: 0.4258 - acc: 0.8359 - val_loss: 0.5824 - val_acc: 0.6780\n",
      "Epoch 74/100\n",
      "396/396 [==============================] - 0s - loss: 0.4093 - acc: 0.8611 - val_loss: 0.5823 - val_acc: 0.6856\n",
      "Epoch 75/100\n",
      "396/396 [==============================] - 0s - loss: 0.4143 - acc: 0.8712 - val_loss: 0.5828 - val_acc: 0.6856\n",
      "Epoch 76/100\n",
      "396/396 [==============================] - 0s - loss: 0.4066 - acc: 0.8889 - val_loss: 0.5818 - val_acc: 0.6818\n",
      "Epoch 77/100\n",
      "396/396 [==============================] - 0s - loss: 0.4025 - acc: 0.8763 - val_loss: 0.5815 - val_acc: 0.6742\n",
      "Epoch 78/100\n",
      "396/396 [==============================] - 0s - loss: 0.3958 - acc: 0.8611 - val_loss: 0.5838 - val_acc: 0.6780\n",
      "Epoch 79/100\n",
      "396/396 [==============================] - 0s - loss: 0.3972 - acc: 0.8763 - val_loss: 0.5980 - val_acc: 0.6932\n",
      "Epoch 80/100\n",
      "396/396 [==============================] - 0s - loss: 0.3985 - acc: 0.8535 - val_loss: 0.5794 - val_acc: 0.6894\n",
      "Epoch 81/100\n",
      "396/396 [==============================] - 0s - loss: 0.3827 - acc: 0.8813 - val_loss: 0.5818 - val_acc: 0.6742\n",
      "Epoch 82/100\n",
      "396/396 [==============================] - 0s - loss: 0.3910 - acc: 0.8485 - val_loss: 0.5781 - val_acc: 0.6894\n",
      "Epoch 83/100\n",
      "396/396 [==============================] - 0s - loss: 0.3848 - acc: 0.8737 - val_loss: 0.5815 - val_acc: 0.6667\n",
      "Epoch 84/100\n",
      "396/396 [==============================] - 0s - loss: 0.3719 - acc: 0.8939 - val_loss: 0.5804 - val_acc: 0.6667\n",
      "Epoch 85/100\n",
      "396/396 [==============================] - 0s - loss: 0.3798 - acc: 0.8636 - val_loss: 0.5774 - val_acc: 0.6932\n",
      "Epoch 86/100\n",
      "396/396 [==============================] - 0s - loss: 0.3804 - acc: 0.8914 - val_loss: 0.5814 - val_acc: 0.6894\n",
      "Epoch 87/100\n",
      "396/396 [==============================] - 0s - loss: 0.3755 - acc: 0.8864 - val_loss: 0.5765 - val_acc: 0.6932\n",
      "Epoch 88/100\n",
      "396/396 [==============================] - 0s - loss: 0.3767 - acc: 0.8889 - val_loss: 0.5764 - val_acc: 0.6932\n",
      "Epoch 89/100\n",
      "396/396 [==============================] - 0s - loss: 0.3644 - acc: 0.8939 - val_loss: 0.5767 - val_acc: 0.6932\n",
      "Epoch 90/100\n",
      "396/396 [==============================] - 0s - loss: 0.3566 - acc: 0.8990 - val_loss: 0.5784 - val_acc: 0.6742\n",
      "Epoch 91/100\n",
      "396/396 [==============================] - 0s - loss: 0.3810 - acc: 0.8662 - val_loss: 0.5759 - val_acc: 0.6970\n",
      "Epoch 92/100\n",
      "396/396 [==============================] - 0s - loss: 0.3674 - acc: 0.9015 - val_loss: 0.5760 - val_acc: 0.6970\n",
      "Epoch 93/100\n",
      "396/396 [==============================] - 0s - loss: 0.3429 - acc: 0.9015 - val_loss: 0.5810 - val_acc: 0.6818\n",
      "Epoch 94/100\n",
      "396/396 [==============================] - 0s - loss: 0.3674 - acc: 0.8864 - val_loss: 0.5757 - val_acc: 0.7008\n",
      "Epoch 95/100\n",
      "396/396 [==============================] - 0s - loss: 0.3524 - acc: 0.8813 - val_loss: 0.5802 - val_acc: 0.6705\n",
      "Epoch 96/100\n",
      "396/396 [==============================] - 0s - loss: 0.3341 - acc: 0.9116 - val_loss: 0.5757 - val_acc: 0.6932\n",
      "Epoch 97/100\n",
      "396/396 [==============================] - 0s - loss: 0.3291 - acc: 0.9091 - val_loss: 0.5768 - val_acc: 0.6970\n",
      "Epoch 98/100\n",
      "396/396 [==============================] - 0s - loss: 0.3347 - acc: 0.9167 - val_loss: 0.5789 - val_acc: 0.7008\n",
      "Epoch 99/100\n",
      "396/396 [==============================] - 0s - loss: 0.3490 - acc: 0.9116 - val_loss: 0.5801 - val_acc: 0.6705\n",
      "Epoch 100/100\n",
      "396/396 [==============================] - 0s - loss: 0.3540 - acc: 0.9040 - val_loss: 0.5774 - val_acc: 0.6932\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = np.array([0] * 198 + [1] * 198) #change number of labels here\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy'))\n",
    "validation_labels = np.array([0] * 132 + [1] * 132)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(train_data, train_labels,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "\n",
    "model.save_weights('bottleneck_fc_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c902d390>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXl4TVf3x79bxBBEJGaJIIh5nodKUJSo1lRKFb9WX6Wt\nomi9VcOrKILSamueg6qaZ4JWzEMMiQRJJEHIgCRkvOv3x74nuXNuhptB1ud57uOeffbZZ9+L871r\nrb3XEkQEhmEYhjFEkbyeAMMwDJN/YZFgGIZhjMIiwTAMwxiFRYJhGIYxCosEwzAMYxQWCYZhGMYo\nLBJMoUAIsU4IMdvMvkFCiK6WnhPDFARYJBiGYRijsEgwTAFCCGGV13NgChcsEky+Qe3mmSyEuCGE\niBVCrBJCVBRCHBRCvBRCHBVClNXo/64Q4pYQIloIcVIIUU/jXHMhxBUhxAshhBeAEjr38hBCXBNC\nxAgh/hFCNDZzjr2FEFfV44YIIX7QOd9JCPGvetwQIcQIdXsJIcRiIUSw+twZIURxIUQXIUSoge+h\nq/r9D0KInUKITUKI5wA+FkK0FkKcU48TLoRYLoQoqnF9Q/V3FSWEeCyEmCaEqCSEiBdClNPo10II\n8ZSFhzEFiwST3+gPoBuAugDeBXAQwDQA5QFYAfgSAIQQdQFsVR9XAHAIwD4hRFEhhDWA3QA2ALAH\nsBPAAOUGQojmANYA+FR9/ncAe9XXZUQcgI+IqCyAPgD+I4R4Vz2us3q+y9TzbQbguvq6xQCaA2in\nvucUACr1uYxy47wLYAcR2QHYAiAFwAT1OO0BdAXwuXoOpQEcU8+jCoDaAE4QUQSAUwAGa4w7HMA2\nIko143MzhRQWCSa/sZyIIonoMYCzAC4QkS8RJUE++Jur+w0GsJ+ITqofcosgrYUOkA/iokT0MxGl\nEtEuAJc07vEpgN+I6DJJNgFIVF9nEiI6Q0S31e9vAfAC0EV9eiiAY0S0Q33fGCLyFUIIAKMAfElE\nT9T3PE9EyWZ+Jz5EtE99z0QiukZEF9XjPATwh8YcPAA8JqKlRJRERPFEpHz2jQA+AgAhRBH1fDeZ\nOQemkMIiweQ3IjTevzZwXFr9viqAEOUEyUyVYQCqqc+F64wbovHeGcAktZsqWggRA8BRfZ1JhBBt\n1K6tp2r3z2eQVgMAOAG4b+Cy8gCKA3iQ0fhG0HVH1RFC7FO7kp4DmGvGHABgD4D6aounB4DnRHQ5\ni3NiCgksEkxB5RHkw14TJ0hxeAz50Nekusb7UABziche/SpHRKWJaLsZ990K4G8A1dTun98BCI1x\naxu4JhJAAgAXA+fiAdgoB+r4QAWdPrruqJUA/AC4qOcwXWcOhu4DIkoEsAPSmhgOtiIYM2CRYAoq\nOwD0EUK4q+MQkyEfxOcA+ABIFkJ8oT7XH0AbjWtXQcYS2gCAEKKUOiBdyoz7lgYQQ0TJ6us/1Di3\nBUA3IcRAIYSVEMJeCNFUbeWsA+AphKgihCgihGinjoEEACghhHhHHXz+L4BiGcyhDICXRPRKHawf\nq3FuP4DKQogvhRDFhBCllc+pZhOAkQD6gkWCMQMWCSY/ofuL2WhAl4gCIH8NrwDwDDKI3JeIUtS+\n/v6QcYAoAIMA7NK49gpkXGKFECIa8kH9sTn3hQwQzxFCvIB8oKdZH0QUCqA3gMkAogFcA9BEfXoy\ngJuQsZEoAPMBFCGil+ox10C6y2LVf5piMoBhQoiXkJaMl8Yc4gC8DRnsfqL+bG4a589BBsyvqufL\nMCYRXHSIYQoXQogTALYQ0dq8nguT/2GRYJhChBCiNYAjAJyIKD6v58Pkf9jdxDCFBCHEegBHAXzF\nAsGYC1sSDMMwjFHYkmAYhmGMUjTjLvkDIQSbPAzDMFmAiETGvQxToCwJIuIXEX744Yc8n0N+efF3\nwd8FfxemX9mlQIkEwzAMk7uwSDAMwzBGYZEogLi5ueX1FPIN/F2kw99FOvxd5BwFZgmsEIIKylwZ\nhmHyC0IIUDYC1wVmdZMxatSogZCQkIw7FlKcnZ0RHByc19NgGKaAUuAtCbVK5sGMCgb8/TBM4Sa7\nlgTHJBiGYRijsEgwDMMwRmGRYBiGYYzCIpHPGTt2LObOnZvX02AYppDCgWsLU7NmTaxZswZdu3bN\nk/vn9++HYRjLwoHrAkxqampeT4FhGMYkLBIWZMSIEXj48CE8PDxga2uLhQsXokiRIli7di2cnZ3R\nrVs3AMDgwYNRpUoVlCtXDm5ubrhz507aGKNGjcKMGTMAAKdPn4aTkxM8PT1RqVIlVKtWDevXr8+L\nj8YwTCGBRcKCbNy4EdWrV8eBAwfw8uVLDB48GABw5swZ+Pv748iRIwCA3r174/79+3j69ClatGiB\nYcOGGR3zyZMniI2NxaNHj7B69WqMGzcOL168yJXPwzBM/iAwEMitPbKFQiSEyP4rO2jGBIQQmDVr\nFkqWLInixYsDAEaOHAkbGxtYW1tjxowZuHHjBmJjYw2OVaxYMXz//fewsrLCO++8g9KlS+Pu3bvZ\nmyDDMAWG+/eBLl2A1q2B7dstf79CIRJE2X/lJI6OjmnvVSoVpk2bhtq1a8POzg41a9aEEAKRkZEG\nr3VwcECRIul/bTY2NoiLi8vZCTIMky95+hTo1QuYMQM4cgSYPh0YOxZISLDcPQuFSOQlwoAZotm2\ndetW7Nu3DydPnsTz588RHBycY8VCGIYpuNy+DXTqBCxbBjx7BsTHAx4ewAcfAP/5D9CiBXDlChAd\nLS0LI86HbMMiYWEqV66MBw8eAIDBh39sbCyKFy+OcuXKIT4+Ht9++61BYWEYpnBx5AhQpowUgjp1\ngCZNgIYNgTlz0vuULQt4eQHNmgEDBwLJyTk/D4uLhBCilxDCXwgRIISYauC8nRDiLyHEDSHEeSFE\nA0vPKTeZNm0a5syZA3t7e+zatUtPAEaMGIHq1aujWrVqaNSoETp06JCp8VlQGObNxMcHGDYM2LgR\nePgQWLEC+OMP/RipEMAvvwDFiwOffJLz7nGLbqYTQhQBEACgG4BHAC4BGEJE/hp9fgIQS0RzhBCu\nAH4hou4GxiqQm+nyGv5+GKZg4ugInD4NuLiY1//VK6BrV/n68cf09vy+ma4NgEAiCiGiZABeAPrp\n9GkA4CQAENFdADWEEBUsPC+GYZh8S2gokJQE1Kpl/jU2NsC+fcCBA4Daw50jWFokqgEI1TgOU7dp\ncgNAfwAQQrQBUB2AIxiGYd4Q5swB6tZNf33xhen+Pj5A+/aZX35foQJw9WrmxCUj8kNluvkAlgkh\nrgK4CeAaAIP5KmbOnJn23s3NjevYMgyTb/jnHyAyEnjvPf1zf/0FzJ8PNGoEpKQAbm5SKOrWNTyW\nIhJZ4exZb3h7e2ftYgNYOibRDsBMIuqlPp4GgIhogYlrggA0JqI4nXaOSWQB/n4YxrKoVMC8eVIE\n6tSRv+Q1SUoC7OykgNjYyLYZM+Txr78aHrNdO+Cnn4C33sr+/PJ7TOISgNpCCGchRDEAQwDs1ewg\nhCgrhLBWv/8UwGldgWAYhslpVCr5qz47PH0KvPMOcPgwcO0a4O+vv7Ht9m2gZs10gQCAzz8Htm0D\noqL0x0xIAG7eBFq1yt7ccgqLigQRpQIYD+AogNsAvIjITwjxmRBijLpbfQC3hBB+AHoC+MqSc2IY\nhgGARYuA8eOzfv3p03JDW8uWwKlTQO3agKsrcOOGdr9r14DmzbXbKlcG3n8f+P13/XGvXgXq19cW\nlbzE4jEJIjoMwFWn7XeN9+d1zzMMw1iarVuBxETD56ZOlUtQx4/XDx6rVHKJ6YoVwPr1Mk2GQuvW\nwKVLQNu26W2GRAIAvv4a6NkTmDRJ7nFQyE48whLwjmuGYfIN0dHAunWWv09AABARAYSHy3tqkpoq\nN62tXg0MGAA8fy7bVSrgxAmgRw/g6FG5E1pTIADpIrp8WbvNmEg0biwD2V5e2u3nzrFIMAzDGGT1\namD0aPlgtSQ7d0oBaNUKuHBB+9zNm0ClSsDFi9KaaNECmDJFxhUmT5arl06eBKrpLuZHuiWhoFIB\nvr4ybYYhJk4EPD3TYyNEbEkUOmrWrImTJ09ma4wNGzagc+fOOTQjhsmfEAFr18pUFN9+a9l77dwJ\nDB4sH8Y+PtrnzpyRq4qKFwd+/lk+xIUA9uyR4jV+PFDUiKO+USNZ50FJzHz/PlCuHGBvb7h/z55S\nbLp3Bx49kuk3VCqgRo2c+qTZh0WiAEBEnKOJeeNRHtZr18qiOqdOWeY+iqupY0fTIqHw3nvAggXG\nrQFNrK2lG0lZBmvM1aQghNwl3a2bDIAvWJC1TXSWhEXCgijlS/v27QtbW1ssWrQIFy5cQMeOHVGu\nXDk0b94cp0+fTuu/fv16uLi4wNbWFi4uLti2bRv8/f0xduxY+Pj4oEyZMrA39pOEYQo4a9dKV1Ox\nYnKH8rRpWUtW9+ef0m1ljJ07ZcZUKyu5H+HiRRmHAOT9dEUis2i6nDISCUDO4/vv5ZLY3buBfOc0\nUNJX5/eXnKo+xtrzCzVq1KCTJ08SEVF4eDg5ODjQ4cOHiYjo+PHj5ODgQJGRkRQfH0+2trYUGBhI\nRERPnjyhO3fuEBHR+vXrqXPnzlm6f37/fhiGiCgujsjOjujRI3mcmkrUrBnRrl2ZH+v994l69DB+\nvkkTojNn0o/r1CHy9ZXv/fyIatTI/D012bCBaMgQ+b5nT6I9e8y/Ni6OKCkpe/fXRf0MyPKzNz+k\n5bA4Ylb2bTf6Ieu7lkn9c2jz5s3o06cPevbsCQDo1q0bWrVqhYMHD2LAgAGwsrLCzZs34ejoiEqV\nKqFSpUrZnjfDFAT+/FMW2KlSRR4XKSJ3MU+YALz7rn4MQKUC7t3TT2uhWAJKRUldt83du7KAT8eO\n6W2Ky6lx4+xbEYAMhs+eLe9vjiWhSalS2bu3JSgUIpGdB3xOEhISgh07dmDfvn0ApHikpKSga9eu\nsLGxwfbt27Fw4UKMHj0anTp1wqJFi+DqyltImDeftWulIGjSs6dMWLdrl6zGpomXl6zOFhkp3VMK\nfn6Ara1MhREUpJ/oTnE1aVQAThOJMWPkBrmuXbP3WVxd5U7sO3ekG8uxgKcr5ZiEhdEMODs5OWHE\niBGIjo5GdHQ0YmJiEBsbiylTpgAA3n77bRw9ehRPnjyBq6srxowZozcGw7xpBAbKdBZ9+mi3CyGX\nnC5erB2bIJJtgEyqp8mZM7KUp+5SVIXdu+XSV00UkSCSIpFdS8LKSi6bXbVKBrsL+n9fFgkLo1m+\ndPjw4di3bx+OHj0KlUqFhIQEnD59Go8ePcLTp0+xd+9evHr1CtbW1ihdujSKqH/uVKpUCWFhYUi2\nRG1ChsljfvlFLnvVtAgUPDyAmBi5wUzh7Fm5xHTSJGD/fu3+iruoVSt9kYiMlC4q3eKPjRrJ5adX\nr8pf/rVrZ/8ztWoFbNqUOVdTviU7AY3cfKGABq737NlD1atXp3LlytHixYvp4sWL1KVLF7K3t6eK\nFSuSh4cHhYaG0uPHj6lLly5kZ2dH5cqVI3d3d/Lz8yMioqSkJPLw8CB7e3uqUKFCpu6f378f5s3l\nxAmi27dN9/HxIapUiSgiwnifFSuI+vdPP+7Xj2jlSqKrV2XQWUGlIqpalejePaIjR4i6dNEeZ/t2\nIg8Pw/fo2pVo8GD5ygm8vGRUZMuWnBkvOyCbges8f/ibPdECKhJ5DX8/TF7h4UE0ZYrx869fE9Wr\nJx/epoiLI3JwkA//gACiChWI4uPTReHuXdnv3j15rFIRRUYSlSlDlJKSPs4nnxAtW2b4HtOnExUp\nQvTLL5n7jMa4f18+XdULFPOU7IoEu5sYhskWKpXh9tu3DccFFGbMkK6ewYNNj1+qFPDpp3L387Jl\nMsBsYyN9/R4e6S4nxdUkBODgIIPeAQHyHBFw7Jjc2WyI9u3l58iJ+g2ATOExdarxokIFiUKxuolh\nGMuwezewZo1+bCA+XibPi4qSD98iOj9Hz58HNm6UeY3MYfx4uUQVkOKj4OEBLFkicyDpLl9Vgtf1\n68v0GMnJ8r0hOnSQQtGggXnzyQghZBGiNwG2JBiGyTJbtsgHPumsMvf3B+rVk3mLAgP1rxszRloG\nFSuad59q1aQg9OuXvpcCkOksLl+WmVqVlU0KmsHr48elFWFspVG5cjI4ritmDFsSDMNkkbg46cIp\nUgQICwOcnNLP3b4NNGwof71fuiT3Dig8eCA3tA0alLn7/fGH/kPexkamsVi7Fnj5UttSaN1a7rEA\n5DwN1Z5mMoZ1k2GYLHHggHTTtG2rn9r79m3pumndWr++ghIbyOz+gRIltIvzKHh4AHPnSrHQHLNF\nC+nOSkiQyQKNxSMY07BIMAwDwHgA2hg7dsigc/Pm+iJx5460JAztV1BcPzlFnz6ycJBu0LlMGcDZ\nWcY+qlbVdlMx5lPgRcLZ2RlCCH4ZeTk7O+f1XxFTAEhOllaBbpU0Y8TFyYd9v36GRUJxN7VsKWs+\nK0V1UlNlwZ6cFInq1WWFOHVKNC1atwZ++gl4++2cu19ho8CLRHBwcJ7v4cjPr+Dg4Lz+K2IKAPPm\nyV3HK1ea13//fpkkz95eXyTi44EnT2TepLJlZe6iO3fkuWvXZNU3Q1XdssOhQ4ZXLrVuLVc2sasp\n6xR4kWAYJnvcuAEsXy7zFvn7G16NpMuOHemBZxcXmTojKkoe+/kBdeqkZ27VXWWUm7/qW7WS88ip\n/Q+FERYJhinEJCcDI0fKimg1awLDhwPr15u+JjYWOHEifbVQkSJA06bA9evyWIlHKGgGr01taLME\nrVoBf/8t4xNM1mCRYJhCzI8/yoDuqFHyeNQoYMOG9EpthlBcTeXKpbdpupyUeISCsqnt1SvgwgXA\nzS3HP4ZRihbVzy7LZA4WCYYppEREAEuXau8/aNRIrgQ6dsz4dZs26dd3aN483ZJQlr8qNGsmrYuT\nJ+V7/lVfsGCRYJh8zL59xus1T54MXLmS9bH/+kuuCtItijN6tNycZgh/f3lP3XxLpiwJGxsZo1i8\nmFcZFURYJBgmH3PoEDB9utwQpsnNm8CvvwIffaR/zlx27jScXG/IEODoUVl/QZelS4GxY4GSJbXb\nGzSQleAiI6WF4uKifb51a8Dbm1cZFURYJJhCTXi4XLKZXwkIkPGBbdu025csAb77Ti77nDlT+5xK\nJXcYHzokX0ePynKemkREyCI7vXrp39POTvrxt2zRbo+MBLZvlyKhS7FiMlfTjh0y86mVlfb5Vq2k\nm6lNG7M+NpOP4NxNTKHmyy/lJix1pdh8R0CA3MPg6SlXIQkh9yDs3i2XqqamypVF778v02M8ewaM\nGAE8fCg3mQHyF/7QocAPP6SP+9dfQO/e+haBwldfAX37SveQEl/47TdZ+rNSJcPXNG8ObN5sOJPq\nO+8AL14A1tZZ/iqYPIItCaZQc/++fOVHXr2SD/3Ro+Xx8ePyz19/lS6h8uXlA3vZMikgx4/LfEXK\nclTFkjh4UGZcffo0fWxjriaFNm2ARYvkwz08HEhMlGVGv/7a+DXNmsla0ZrxCAVnZ1lfgSl4sEgw\nhZrgYJmVND8SGCh9+1ZWsl6Cpyfw+rX8RT9hQnq/wYPlqqQhQ4Dff5d1DDR/sdeqBXz4oUyCB6S7\nmgylsdDko4+ka6l3b3nPpk0NC4CCUs/ZVB+m4CFINxF8PkUIQQVlrkzBICZGppVo0SJ7q4Qsxc6d\nMhbx11/yl3yNGlIQgoKAvXu1+756JQXEwcHwWBER0g10+TJw+DDwzz/6MQdDEEmX3IoVwJEjQI8e\nxvvGxso0HP7+b0ZFtjcFIQSIKJM5d9PhmARTaAkOljmE8qslERCQ/rAtXhz4/HNZ8vPUKf2+Njby\nZYxKlWR1txkzpPvoyy/Nm4MQckXTW29lvHy1TBlZv6F2bfPGZgoGLBJMoSUoSGYp9faWqabt7fN6\nRtoEBGhXWvv8c7kSS7MtM0yaJPcrJCYaXtVkDCsr8wsEvf9+1ubG5F84JsEUWoKDZb6iWrXypzWh\naUkA0pU0f37mi/Uo2NrKuMSIEbKAD8OYA4sEU2gJCspdkZg0SS5NNRddkcgJPvlErnRiGHNhkWAK\nLUFBMhjs4mJ5kQgNlauTZswwr39UlNwDUaGCZefFMBnBIsEUWnLT3XTggNycdvAgcOuW9rnUVH0L\nQ7EisupaYpicgkWCKZQQSZGoUUOKhKU31O3fDwwbBkybJnMxac5jwgS5B0EzdYYlXE0MkxVYJJhC\nSWSkXFZqa2t5S+LVK+DMGbl57fPP5W7of/+V5xYulKurXFzSd1QDLBJM/oFFgimUKEFrQOY4evRI\nVmkzBz8/uc8gJcW8/idPyqW2dnZyVdGsWdKi2LxZpro4dEjubt65M/0aFgkmv8AiwRRKFFcTIDOY\nVq1q/sqjH3+UO6E//1y6izJi/37AwyP9+KOP5L6MCRNkjMLRERg4ENizJ93lxCLB5BcsLhJCiF5C\nCH8hRIAQQi/FlxDCVgixVwhxXQhxUwgx0tJzYhhNSwIw3+UUHi6D0FevylQe//uf6f5E+iJhZQVs\n3Sqrvyl5jqpVk++PH5epvgMD5cY3hslrLCoSQogiAFYA6AmgIYChQoh6Ot3GAbhNRM0AuANYLITg\nneCMRVGWvyqYG7xesUJaAk5OUizWrTNexQ0AbtyQ6bh1rYKmTdMT4ikMGiTrMYSHS9cUl/lk8gOW\ntiTaAAgkohAiSgbgBaCfTh8CoPx3KAMgiojM9PYyTNZQlr8q6FoSr14Brq4ynqAQFwesWiVrLQBA\n5coyWd633wLnzxu+j2JFmLOUdcAAmbjv5k12NTH5B0uLRDUAoRrHYeo2TVYAaCCEeATgBoCvLDwn\nhjFoSWiKxK5dQNGiMv22r69s27BB5k2qVSu9X926wPLlwKhRhsuI6rqaTKG4nH79lUWCyT/kB7dO\nTwDXiKirEMIFwDEhRBMiitPtOFOjTqObmxvc3NxybZLMm4NKJYPUmiKhu+t67Vpg9my5gqlPH+Ds\nWZkNdf16/fEGD5Yrk2bMAH76Kb39/n3g7l2gc2fz5zZ4sFw5tXBhZj8Vw0i8vb3h7e2dcwMSkcVe\nANoBOKxxPA3AVJ0++wF01Dg+AaCVgbGIYXKC8HCiSpW026KiiGxtiVQqonv3iMqXJ0pMlOc8PYkc\nHIjatJHnDRERIcf08ZHHBw7I459/zvzchCDasydz1zGMMdTPziw/xy1tSVwCUFsI4QzgMYAhAIbq\n9AkB0B3Av0KISgDqAsiHOTmZNwXN5a8K5crJuEF0tLQWhg2TS2MBWbIzMRFo3dp4bKFiRel2GjlS\npt/w8gL+/BPo1Clzc6taFZg8WZYPZZj8gEVFgohShRDjARyFjH+sISI/IcRn8jT9AeB/ANYLIdSe\nX0whomhLzosp3OgufwXkw79WLbn0dP16GUvQZNq0jMcdNEjudfDzA65dkzWos4Kmy4ph8houX8q8\n8Rw+DJw7J3c6CyH3NsTHA/PmafcbNEguO/X1lWU+GeZNgMuXMowJLlyQ+xoqVpSb2H74QbqbDLlz\natUCFi/megsMowmLBPPGEhAA9OsnN7y1agV06CCXmQYFyVVEutSqJZe9DtWNmjFMIYZFgnkjiYgA\n3nkHmDMnfZ/C4cPAW29JV5NuTAKQQeb//lcGsRmGkXCCPyZLuLnJ9BG6BAcDb7+d27PR55NPpEXw\n6afpbXXrysBypUoy86suDRtKkWAYJh0OXDOZJjVV5iM6dAjo1k373MGDMgAcF5czVdXi44EPP5Rp\nMgwxaBAwZox2W2iozI0UHi7nyTCFGQ5cM7nO48ey9kJIiP65kBD5QI+KyvoSUE28veX95s7VPxcX\nJy2GIUNk8SCFjRtlzIEFgmGyD4sEo8Xjx0CVKqb7KOIQHKx/TmkLDs4ZkTh+XAafjbmwtm+XKTQm\nTJDHRDJQvXVr9u/NMAzHJBgdWrQAwsJM9wkJAYoUMW5JGDuXFY4fNx3jmDgRWLYsvUrc2bOy+lvr\n1jlzf4Yp7LBIMGmoVMDTp4YD0pqEhMhaCMZEwti5zPL4sZxLy5bG+7RpI5e1/v23PF67Fhg9Omfi\nIQzDsEgwGsTGSqF48sR0v5AQuZTUmEgYO5dZTpwA3N3lJjhTTJwIeHrK+e/ZAwwfnv17MwwjYZFg\n0oiJkX8+fmy6X0iI3FPw6JFc6aSQmCgD1u3a5YxIHDsGdO+ecb9+/aSwTZwol+ZWrJj9ezMMI2GR\nYNJQRMIcS6JOHcDBQQqFQmiozGJaq1bmReLZM2nFKBBlHI9QsLKSgevVq6WriWGYnMMskRBC/CWE\n6KOuWc28oZgjEkRSAJyd5UtTDIy1Z0RcHNCoEbBgQXqbnx9gbS2LAZnDqFFSIHr1Mv++DMNkjLkP\n/V8BfAggUAgxXwjhasE5MVlk8mT9FNeZISZGPphNuZuiooDixeW+hBo19EWiRg259DUxUcYIzMHT\nU25+8/QEbt2SbYoVYW4AukwZYM0aOX+GYXIOs0SCiI4T0TAALQAEAzguhDgnhBglhOD/lvmEixfl\nEtCsEhMj3UimLIngYGkpAMYtCSHMtyaePZNLWFeulBvmRo6UG/WOHzcvHsEwjGUx230khHAAMBLA\nJwCuAVgGKRrHLDIzJtOEhQE3b2b9+pgYoEED05aEIgSA/FNzQ50pAQGAe/dk6m5N5s6VOZZcXGSe\nJXt72Xb6NNC1a9Y/C8MwOYO5MYndAM4CsAHQl4jeJaLtRPQFgNKWnCBjHiqVFAlf34z7GiMmBqhf\nX2ZQNZYmS1ckDFkSyjndHdmennJV1Jw5clVUcDCwaRPw/ffyvBAy+LxkiRSNChWy/lkYhskZzE3L\n8TMRnTJ0goha5eB8mCzy7JmME7x8Kes029tnfozoaKBJE8DGRr53cNDvkxmR0LUkfHxkGo1ly6Sl\nYGsLjBsns7IqVK8uheLly8zPn2GYnMdcd1MDIYSdciCEKCeE+NxCc2KyQGiofMA2bpx1l1NMjKyl\nULmy8biErhA8fCitjtRUuRzWySn9nKZIxMXJIkB9+shNcu3bA5cuyWC7LoMGAf/3f1n7DAzD5Czm\nisSnRPRMo8UjAAAgAElEQVRcOSCiGACfmujP5DJhYfIB3bhx1l1OikhUqWKeSJQuLTOtPnsmBcLB\nQa58AvRF4tIluYKpeHFZ/W3OHCkwmtlbGYbJf5jrbrISGgUdhBBWAIpZblpMZgkNBRwdZeGc69ez\nNkZMjHRTVa5sPHitKRJAuhgkJhpuV/DxkdaDJpxfiWHyP+ZaEocBbBdCdBNCdAOwTd3G5BNyw5KI\njZVioJkCXBEDXfGoUkXGNRIS5LEhkWAYJv9jrkhMBXAKwFj16wSAKZaaFJN5FEuicWO5IU0zxYW5\naMYkDFkSmvsgFJQNdcpGOgUrKzmf0FAZszh/nkWCYQoiZrmbiEgFYKX6xeRDFEvCzk7GBoKCzE9p\nAUhRefFCXl+limGXleY+CAVnZ+DBA2lhNGumf05xOZUsKVN6MwxTsDB3n0QdIcSfQog7QogHysvS\nk2PMR7EkgKy5nGJj5dLXokUztiQ0MeZu0jzHriaGKbiY625aB2lFpABwB7ARwGZLTYrJHCqVXF2k\n/FJv0iTzy2Cjo6WrCTAekzAmBMHBxq2MkBDg3DkWCYYpqJgrEiWJ6AQAQUQhRDQTQB/LTYvJDE+f\nAmXLyrKdQNYsCSUeARjfJ2HKWnj40LiAsCXBMAUXc0UiUZ0mPFAIMV4I8T44HUe+QYlHKDRpkj2R\nsLcH4uPTVyYpGBIJe3tZX7pkSblvQhNnZxlEv3dPljRlGKbgYa5IfAWZt+lLAC0BDAfwsaUmxWQO\nzXgEANStK4Xj1Svzx9AUCSFkqoyICO0+hkRCyfiq2w7ItmvXZEC7GO+qYZgCSYYiod449wERxRFR\nGBGNIqIBRHQ+F+bHmIGuJWFtLYXi9m3D/f/8E7hyRbtN2UinoBu8TkiQcYsqVfTHMyYSTk5SRNjV\nxDAFlwxFgohSAXTKhbkwWUTXkgBMu5xWrQIOHdJu07QkAP3gdWioDIxbWemPZ0wkihWT47BIMEzB\nxdy0HNeEEHsB7AQQrzQS0V8WmRWTKcLCZF4kTUytcLp9WyYD1ERXJHQtiQsX9O+hMHKkYfEAgHnz\nzKtTzTBM/sRckSgBIAqAZhkYAsAikQ8wZkkcOKDf9/lzIDxcP413TIy2cOhaEvv3Ax4ehu/ftq3x\nuY0YYXruDMPkb8zdcT3K0hNhso5uTAKQweLr12VKDM00GnfuyOWyuiKhuU8CkJbEtWvyfXIycOSI\nLAbEMEzhwiyREEKsg7QctCCi0Tk+IyZT6G6kU6hYUe6gDg4GatZMb79zB+jRA9i3T1tATLmb/v0X\nqF3bcNCaYZg3G3OXwO4HcED9OgHAFkCcpSbFmM/TpzLfklLHQZPmzdOtAYXbt4HWreWehqdP09tN\nBa5NuZoYhnmzMUskiGiXxmsLgMEAuGxpPsBQPEKheXP9RH23b8uaE7o1qE1ZEiwSDFN4MdeS0KUO\ngIo5OREmaxiKRygYsyQUkdCMSxgSiYgIWXL05UveMc0whRVzs8DGCiFeKi8A+yBrTDB5TEaWhKZI\nPH8uH/hOTtoioVLJdju79L7Fi0uX1KZNsi51kaz+nGAYpkBj7uqmMpaeCJM1TFkSNWrIHEzPngEV\nKsigdf368oHv7AwEBsp+L18CpUrJNOGaVKkCrF0L/PqrRT8CwzD5GHMtifeFEGU1ju2EEO+ZeW0v\nIYS/ECJACKFnfQghJgshrgkhrgohbgohUoQQdobGKiwQAWfPGj737JlcbaRgypIQQi6FVawJxdUE\naFsSuq4mhcqVgagooFu3rH0OhmEKPuY6EX4gohfKARE9B/BDRhepM8euANATQEMAQ4UQ9TT7ENEi\nImpORC0AfAvAWz1+oeXRI+Ctt4AdO7TbieTmtLffBqZNk/sXTFkSgLbL6fZtoEED+d5ckXB318/u\nyjBM4cFckTDUzxxXVRsAgeoaFMkAvAD0M9F/KIBtZs7pjSUgQO57+PJL7WWq69bJ43v35Kold3fp\nMjJmSQDalsSdO4YtCd2NdApdugCjeScMwxRqzBWJy0IITyGEi/rlCeBKhlcB1QCEahyHqdv0EEKU\nBNALwC4z5/TGEhAA9OwpcyJ9/rm0IEJDgalTgfXrgapVgYMH5bLU169N147WtSQUkShXTo77/Llx\nS2LMGGDQoJz+dPmXpNQkPHzxMK+nwRQyAqMCM31N+MtwvEh4kXHHHMBckfgCQBKA7ZDWQAKAcTk8\nl74A/insriZAioSrKzBzJuDnB3h5AZ9+CkyYIKvOATL4PG0aEBlpeCOdQr16UmDCwmSAWsnPpNSB\nCAkxLhKFDa9bXhi4Y2BeT4MpRDyNf4oGvzbAg5gHZvV/kfACU49NRa2fa2H+P/MtPDuJuaub4gFM\ny8L44QA08406qtsMMQQZuJpmzpyZ9t7NzQ1ubm5ZmFL+JyAA6NxZliNdtw5wc5OxhKkGFh1bW5se\ny9paWg/btsmVTZp5nJQNdSwSknOh53Dl8RW8SHiBsiXKZnxBDpGcmozrT66jdbXWuXZPxvLsD9iP\nR7GPAAACAgMaDIB9SXutPttvbUeKKgXnQs+hVrlaRsdKUaVg1ZVVmHV6FjzqeuB3j9+x7vo6g329\nvb3h7e2dY59DEOmlZNLvJMQxAIOUX/lCiHIAvIioZwbXWQG4C6AbgMcALgIYSkR+Ov3KAngAwJGI\nXhsZi8yZ65uAqyuwe3d6kHnzZqBNG1lIKCuMGQNcvChdT+s0/l2NGyfv9egRYGsLfPdd9udekGn6\nW1M8iXuC1X1Xo69r31y77/Zb2zFyz0hETI6AbXHbXLsvYzmCnwej+e/NMaiB9NcGRAWgfvn6WOmx\nUqtfu9XtYFvcFnXs6+CXPr/ojUNEOHTvECYfnYwqZarAs4cnmlZuiucJz+Ho6YiYqTGwtjL9S1EI\nASISJjuZwNxU4eU13UBEFCOEyHDHNRGlCiHGAzgK6dpaQ0R+QojP5Gn6Q931PQBHjAlEYSI5WbqA\nXFzS24YPz96YzZvLQkO64yjuprg4uaeiMBObGIt70ffwTYdvcDLoZK6KxJabW1DMqhh2++3Gx824\nKrA5xCfFY5PvJgxvMhyli2V/+V2qKhWrrq7CBw0/QLmS2mb1mZAzOHLviMHriogiGNdmHCqXrqzV\nfiDgAPq59sMffeUjLiIuAvV+qYc5XeegvE15AMC96HsIeh6EPwf9ia8Of6U3dvTraAz5cwgevniI\nxT0Wo3ed3hBqV4BdCTs42znDN8IXLau21Lpu2fllGNJoCCqVrpS1L0P3M5rZTyWESHMbCSFqwEBW\nWEMQ0WEiciWiOkQ0X932u4ZAgIg2ENGH5k/7zSU4WAamTcUZMouSUkMJWitwTCKdi+EX0axyM/R0\n6YlTwady7b5Rr6JwOuQ0FvdYjC03t+TafQs6q66uwuzTs+G6whVrr61Fqio1W+NdenQJU45NgesK\nVyw7vwxJqUkIjApE/+39MWL3CFhbWcPG2kbvdfXJVSw+t1hvvP2B++FRNz3hWaXSldC/Xn/8fvn3\ntLYtvlvwQcMP0KZaG9yNuov4pHitMbbd3AYbaxvcHHsTfer2SRMIhfaO7eET5qPVFpsYi/+e+i9K\nFSuVre9DCyLK8AW56ughgE0ANgMIAdDTnGtz6iWn+uazfz9Rz545O2Z8PFGRIkTBwdrtPj5ErVoR\nde9OdORIzt6zoDHn9ByadGQSJaUkUZkfy1BkfKRZ1yWmJNJs79n0KumV3rln8c9owT8LKFWVavT6\nlZdW0uCdgyk+KZ7s5tvR49jHWf4MhYXk1GSqsbQGnQ89TxfCLlDHNR2p6cqm9CT2iV7fFwkvaKnP\n0gzH/PHMjzTh0AS6GXGTem7qSdWXVCeHBQ40/+x8ep382uh1tyJuUbXF1SglNSWtLTYxlkr/WJpe\nJLzQ6nsz4iZVWVSFEpITSKVSUZ2f69D50PNERNRudTs6FXRKq3+vzb1o5+2dRu+9+spq+nDXh1pt\nu+7soh6bemi1qZ+dWX72mpsF9jBk1te7kMHlSQAKvWvIEgQEZD32YAwbG8DHR79kqWJJGNsnUZjw\nCfNBe8f2sLayRsfqHXE65HSG16hIhdF7RmOG9wyD/ff478HU41Px3QnjwZ4tN7dgWONhsLG2QT/X\nfvC65ZWtz1EY+Nv/b1QtUxVtHduiTbU2ODvqLNpUa4NlF5bp9V11ZRUmHJmA8JfG1stITgWfgntN\ndzSq2AiHhx/G9oHbcWfcHUztNBUlipYwel3Dig1R3qY8zoScSWs78eAE2lZrqxdfalSxERpXagyv\nW164/OgyVKRCm2ptAKitgtB0qyAuKQ7/PPwHPVx6GL13eyftawAZLPeok7Mpm81Ny/EJZB2JSQAm\nQ1oUM3N0Jm8Q8fEZ9zGGJUQCkIFvHWsVlSrJZbGPHhVukSAinA87j/ZO7QEA7jXccSooY5fTdye+\nQ9DzIEzpMMVg/1PBpzCv2zz87f83ll9Yrnc++Hkw/J75oVftXgCAYY2H6bmc1l5bizVX12Q4lz3+\nezD+4Hg8iXui1R4YFYiRf4/Erae3MhwjK5x4cAIf//0x7kffN/ual4kvMXjnYHRe1znt9d2J7/Ay\n8aVZ13v6eGJiu4lpx0IITO04FauurtJy2aSoUrDswjI0rtgYBwMPGh0vKTUJPmE+eMv5rbS2do7t\nULGUeYmudf/e9gdou5o0mdhuIjzPe2Kz72YMbzI8zYWk6zoyJjSa1CtfDzEJMYiIiwAgf7QcCDyA\nPnX7mDVvczE3JvEVgNYAQojIHUBzAIV+P4MxuncHjh7N2rWWEglDFCkiU3o8eVK4RSIgKgCli5VG\n1TJVAQBda3bFyeCTJq9ZfmE5/vb/G3uH7EXvOr314hhEhFPBpzCowSAcHn4YC/5dgD/v/KnVZ+vN\nrRjUYBCKWRVLu2/YyzDcjbwLANh1Zxe+P/U9ph6fitAXoTDGy8SXGHtgLOKS4tDo10aYe2Yuwl+G\nY8LhCWi/pj2Cngfht8u/Zfp7yYhrj69h6K6hsC9hj7ar22LSkUmIeR1j8pqk1CQM2DEAZYqVwY9d\nf8SPXX/EHPc5eBL3BK4rXPH75d+Rokoxer1PqA+exD3Be/W0U8e52Lugc/XO2HBjQ1rbrju7UMOu\nBqZ1mob9gfuNjnkh7AJcHVxhVyJrKeOGNh6Kv/z+QkJKQtqD2phI9HDpgRRVCn6/8juGNR6W1t7e\nSYoEqVdwmhIahSKiCNo5tksTl8uPLqO8TXmTS2mzhDk+KQCX1H9eB1Bc/f52dvxcmX2hgMQkVCqi\nsmWJPv88a9c7OhIFBeXolEzSvTsRQJSSknHfN5V119bRBzs/SDtOSU0hu/l2Bn3cREQnHpygqour\nUlBMEBERJSQnUOkfS9Pz18/T+tyNvEtOnk6kUqmIiOja42tU4acKNPfMXHqV9IpUKhU1+KUBnQ05\nqzX214e/pu9Pfk9ngs9QhZ8q0LXH12jGyRk0eOdgo/OfeHgijf57NBER3Yu6RwN3DKSis4vS2P1j\nKSIugu5H36cKP1WgpJQkreuiXkVR05VNycnTyeDLfb17ms9clwfRD6jq4qq0684uIiJ6EvuEPtv3\nGVVaWImuP75u8BqVSkXD/xpO7257l5JTk/XOX310ldzXu1PrP1rr+fMVBu0YRMvOLzN47mzIWar9\nc21KVaWSSqWi1n+0pt1+uynqVRSV+bGMwbgREdEs71k0+chkg+fMxX29O+26s4suh18m1+WuJvuu\nv7aeOq7pqNfu5OlEgVGBlKpKpSqLqlBgVGCG953lPYumHJ1CRETfn/w+7b0myGZMwtwH9G4AdpAu\npjMA9gA4mJ0bZ3qiBUQkoqJkkLh6dSkYpli7ligkJP04Lo6oRIncfWD/3/8R2drm3v3yI2P2jtEL\nbvbd2pe8bnrp9U1MSaR6K+rRHv89Wu1dN3SlfXf3pR3/duk3GrF7hFafe1H3aMD2AVR9SXWa7T2b\nnJc46wW1L4dfpqqLq1LFhRXp2P1jREQUnxRPzkuc6cSDE3rzuRVxi8r/VJ4i4iK02nUfiO1Xt6cD\nAQe02uadnUdD/xxKIc9DDL7WXl1LVRdXpaF/DqWgmCBSqVSkUqnoWfwzqru8Li2/sFxvPjtu7aBq\ni6tRcEyw3rlpx6ZR+9XtKT4pXu+cgkqlorH7x1K3Dd0oMSVR61xQTBA5LHCglwkvjV7b+o/WtMd/\nD/0T8g+5LHNJCyh3XtuZDgYcNHid23o3ve8ms6y+spre93qfZp6aSZOOTMqwv+5nIyIavHMwbby+\n0SyhUTh67yh1XtuZiIia/9aczgSf0euTKyJB2g/rLgDeBVAsOzfOwn3N+tLymkuXiJo2JapZk8jX\n13TfBg2IJmv8gLl+nahhQ8vOT5fZs4mcnXP3njmF100v+nx/Fk02DRr/2pguhl3UavM850mf7ftM\nr++ifxfRO5vfSbMQFOacnkMTD09MO/5g5we07to6g/c7E3yG2q5qS/87/T+9cyqVijqt7USbbmzS\nav/rzl/U4JcGWtaASqWirhu60s/nf87wM664sEJrJUxiSiJVXVzV6K9+hdjEWPrh1A9Uam4pwkwQ\nZoLETEHTT0w3es1Sn6VUb0U9inoVRUTy4f7Bzg+o3op6Zq0aS0lNofe83qNhu4aliah3kDc1XdmU\nvjv+nclrt93cRl3WdaH+2/tridiCfxYY/LfyOvk1lZpbyqjwmEvM6xiynWdL9VbU01ulZC5LfJbQ\n2P1jzRYaIrl6q9TcUhQUE0T2C+wNWmi5LhJ59SooIrF9O1H//kRffEH044/G+6WkEBUvTlSpElGS\n+v/9jh1E77+fO/NU2LCBqFkzy41v6BdTTvHlwS+p2uJqeg/szKD8J9Od57XH16ju8rpabeEvw8lh\ngQMFRAbojfNPyD/U7Df5RapUKqq4sKLBX9NZRaVSUY9NPeh/p/9HQTFBFBQTRGuurqHGvzY2+GDQ\n5WncUyo7ryzFJsYSEdGmG5uo24ZuOTY/XSYfmUwd1nSgqcemkv0Ce5rlPYviEuPMvv5V0ivqsKYD\n/Wfff+h9r/ep+pLqtNV3q8nlxERESSlJ5OTpRA4LHNI+KxHR7ae3qfqS6nr/Vk4+OEltV7XN3Icz\nQv/t/ansvLJ6bj1zOR96npr91oxa/dEqU0LT6NdG9OneT/WWwypkVyS4KGUO8+CB3C3t4QHsNx4r\nw8OHcnVR7drAoUOyLTeD1gotW8raFZbgecJz1FxWE1cfX7XI+L5PfREeG4570feyPMbF8ItoXqV5\nWvBYoUmlJhAQGLhjYNrKnSnHpmBMyzGo41BHb5zW1VrjfvR9RL+Oxp1nd1DKuhSc7ZyzPC9dhBD4\nudfP2HJzC9zWu8FtvRvm/TMPK/usRNEiGSdOqFCqAjpW74i//f8GEckVQu0nZnhdVlnw9gI0qtAI\nz+Kf4ebYm5jRZUamNniVtC6JvUP24m7UXbSp1gb+4/wxtPFQFBGmH1nWVtaY7T4b0ztP19qJXb98\nfVgJK71VXieDTsK9hnvmPpwRvmjzBca3GZ9hmgxjNK/SHAFRAbgXfQ8dnTqafV17x/ZYe21tji99\nVTA3LQdjJvfvywdvly7ArVsyS2v58vr9FEEYOlSWCH33XdnWpUvOzENFKkS9ikKFUhVM9mvYEFim\nv7w8R/jh1A94Fv8MPqE+aFGlRY6OTUTwjfDF27XexqngUwYf3AopqhTEvI4x+F34hMr9EboUEUVw\n9bOrWOKzBG1Wt0HvOr1xJuQM/Mb56fUFgGJWxdDBqQNOB59GeGx4jj14NHEt74o74+5k+frhjYdj\no+9GVCtTDa9TXqctvbUERUQR/N7394w7msDBxgEnPza9yswQI5uN1GsTQsCjrgf2B+xH40qN09pP\nBZ/CD10yrJ9mFm413OBWwy3L1xezKoZmlZvBydYpU0KjiETP2iZT6WUZtiRymAcPgFq1ZFqNbt3S\nrQRdFJEYNAjw9pbLUHPSkvjt8m/otjHv6o76Rvhi261tmNFlhkUsicdxj2ElrDC00VCcDDL9IPn1\n0q9ot6YdElIStNoTUxKx+eZmow9LG2sbTH9rOm5/fhtli5fFbx6/mfw17F7DHaeCT6VtzMpvvOv6\nLnxCffDfU//F1+2+zvBX+ZuGR10PraWw8UnxuP7kOjpWN/9Xu6X5tMWnGNNyTKau6eHSA5PaT9LL\nMJtTFK5/JbmAIhKAaZeTIghlygDvvy8zveakSGz23Qz/SH/4RvjqnVPcIpaCiPDFoS8w2302erj0\nwJXH5tSnyhy+Eb5oUqkJ3Gu6wzvYW4lbGWRfwD4kpSZh0blFWu1Lzy9FXYe66Fqzq8l7VS5dGSt6\nr0DvOr1N9nOv6Y4TQSdwOvi0RSyJ7FKqWCn0de2Lu5F38VGTj/J6OrlOF+cuuPX0FlZfXY2NNzZi\n/j/z0bxKc9hY2+T11NIY2Wxkhv8edalmWw0L3l5goRmxSOQoycly97KS/qJ3b7mpLjlZv6+mIIwe\nDSxfDqSmAhVMe4fM4kHMA9yLvocv236JLb7aO3iJCP139MeUY1OyfyMjeN3yQmxiLD5t8SkaV2yM\nu1F39X7FZxffCF80rtgYNexqoKR1SfhFGnYDvUx8ifNh53Fo2CEsOb8EIc9lzdawl2FYeG4hlvZc\nmmNzalGlBUJfhMK+pD2q2ZooF5iHTOs4DX/0/QMlrUvm9VRyneJFi2Ph2wtxJuQMjj84jpAXIZjU\nflJeTyvfwyKRg4SEyAyuxdQx0MqVgTp1gH/+0e+rKRKdOslr6tbVT52RFbbe3IrBDQdjZLOR2Hpr\nK1SkSjt3KvgU4pPisctvV9p2fnMIjArEzts7M+wXmxiLb459gxW9V8CqiBVKWpdEXYe6uBlxU6tf\ncmoyDgUa8cWZwc2nN9GkUhMAptNoHLt/DB2dOqJRxUb4qu1XmHRUPhS+OfYNxrYaCxd7F4PXZYWi\nRYqiS40umf4lmJs0rNgQ/ev3z+tp5BljWo7Bxvc3pr10d24z+rBI5CCariaFPn2AAwe02xISgMeP\nZYI9QArDJ5/op/LOCkSEzb6bMazxMDSq2Aj2Je21ko95+nhiWqdpGNxgMFZeXmliJEn06+i09A4T\nj07EH1f+MNn/f2f+h261uqGDU4e0tpZVWuq5nI4/OI6+2/rieULWsrv4RvimBSCVWIAhNFM2f9Ph\nG1x9fBX/PflfnAs9h287f5ule5tixlsz8FVb/doADFNQYZHIIj4+wNmz2m2GRKJbN+C0ToLQ+/eB\nmjWBohpryyZNAn791fC9Nvtu1vslboyrj68iWZWMdo7tAKiTj6ldTv6R/rj06BKGNR6Gr9t/jZWX\nV+J1svFkvrv9dqPeinpITEnEnXF3cOrjU/jB+wfsu7vPYH//SH+svb4WC7pr+0dbVmmJK4+0RWJ/\ngAzWGCvmohD9OhqePp5abcmpyQiICkCDCrJ0n3tNd5wOOa1lMQFyhdfBwIPoU0cmPCtpXRJLey3F\n3LNz4dnD0yK+6NbVWqN+hfo5Pi7D5BUsElkgORn4+GNgvk4dckMi0bo14OcHxMamtxkKUBctCpQ0\n4Cb2j/TH+IPj8c6WdxD8PDjDuSmpp5XskkMbDcVf/n8hMSURS88vxdhWY1HSuiTqla+H1lVbGy10\nE/UqCv858B/sHboXKz1WomKpiqhtXxt7huzB6L2jcT7svFZ/IsKXh77E9M7T9ap0tajSAlefXNXq\nuy9gH8a1Hmcy8VpCSgL6efXDN8e+0VrffjfqLpzLOqc95B1tHVGuRDm9NfCXwi+hgk0F1CxXM62t\nb92+OD3ydKF2uTBMZmCRyAJr1wL29tKSSEpKb1c20mlSvDjQqhXw77/pbeauYlJWCc10m4mpHaei\n1+ZeiHoVZbR/qioVXre8tLJLOpV1QpNKTbDxxkZsv70dY1uNTTs3sf1EePp4GlwZNP3kdAxpOCTN\nIlFoU60N1vdbj/e83sOuO7vSrt3tvxuPYh9hXOtxemM1rdwUfs/8kJiSCEDGE6ytrDG5w2QcCjxk\nMOtnqioVw/8aDkdbR0xsN1ErAK/palJwr+GutxTWUCZNIQTecn5Lr8oXwzCGYZHIJK9eAbNnAytW\nyAf9eY0f1Pfv61sSgNzRfCY9LGC2SOz2343HsY8xrvU4fNH2C/Rz7Yd3vd416iI6FXwKVctUhWt5\nV632YY2H4cvDX2JA/QFadW/da7ijmFUxHLmv7fK5/Ogy9tzdg1nuswzep0/dPtg2YBtmnZ6Ft9a/\nhTMhZzDxyEQsf2e5wU1ANtY2cLF3SfulrxRGcSrrBEdbR4NWyYTDExD9Ohrr+63HR00/0grA+0b4\noknFJlrXuNfUj0volpBkGCbzsEhkkmXLgI4dpXXw9tvA8eOynciwuwmQu6g1ReLu3YxF4lXyK70H\n77zu81DTriZ6bO6BG09uaPX3jfDFtye+Nbj+fWCDgShuVRwT2k3QahdCYFL7Sfj6yNc4F3oOgPTj\njz84Hj92/dFkfn33mu649tk1fNz0YwzeORjtHNuZ3EDWskrLtE11mr/wlV2wmvxx5Q+cDjmN3R/s\nRvGixdGkUhPYFrfFvw+lOXbz6U2DlsTp4NPYdnMbiAhhL8Pw8MVDPUuIYZhMkp3ET7n5Qj5I8BcV\nReTgQHT3rjw+fpyoXTv5PjJS1pEwlGsuLo6oVCmiV+rszRUqED16ZPpe35/8XqvGgUJyajL9cvEX\nqriwIo3+ezRdfXSVPtnzCVVcWJGWX1huNNmbsVz6KpWKNlzfQI6ejjRoxyCac3oOtV3VNsNEarpj\nJyQnmOyz7Pwy+mzfZ/Q07inZzrNN638+9Dw1/CU99e3TuKdU/qfydCviltb1887OozF7xxARkaOn\nI92Pvq93jzPBZ6jl7y2p7aq29Pn+z2nYrmFmfwaGeVMBZ4HNPb75hmjMmPTj16+JSpcmev6c6OJF\noubNjV/brh3RqVNE0dHyGlOJS889PEflfypPoS9CjfaJeR1D3xz9hsrNL0eTj0ymmNcxmf9AGsQn\nxVbE8O8AABO5SURBVNNs79nksMCBLoVfytZYhvgn5B9q9Ucr2nB9A/Xf3j+tPVWVShUXVqQH0Q+I\niOiTPZ/Q14e/1rs+OCaYHBY40JPYJ1T6x9JGRSxVlUobr2+k6kuq026/3Tn+ORimoJFdkRBkIp1B\nfkIIQXk9VxcXYO9e7f0MPXoA48bJvQ9//gnsNLLfbOpUwMYGeOcdYOxY4IqRTBV3I++iy/ouWP/e\neosmYDMGEVkkqBufFI+Kiyqih0sPvFv3XYxqPirt3Kg9o9CySku0qdYG73m9B79xfihboqzeGF3W\nd0GrKq1wLuwcfP7PR+88wzD6CCFARFn+T80xCTNRqYDwcLm/QZO33waOHTMetFZQgtemgtaPYx+j\n15ZemN99fp4IBACLrfopVawUatjVwL67+/RyIHnU8cDeu3sx/uB4zO8+36BAADIA/8ulX/SC1gzD\nWA4WCTOJjARKl5bWgCbdu8vgtbGgtULHjsDFizJ9uCGReJn4Er239sYnzT8xmOr4TaBFlRZoWbWl\n1gorAHjb5W14B3vD2soaw5sMN3r9wAYDoSJVWjoOhmEsD9eTMJPQUMDRUb+9aVMgKkpaCR98YPx6\nOzuZx8nLC5g7V/tcUmoSBuwYgLbV2uK7zt/l7MTzEYMaDMKLhBd67bbFbTG141QMajjIZPpq+5L2\nmNJxSr7OjcQwbxockzCTPXuA1auBfQYyUgwZAmzfnrHLacIEuYT24kW5ExuQMYARf49AbGIsdg3e\nBasiVpb5AAzDFEo4JpFLGLMkABmXsLICnJxMj6GUCa2jUUTtuxPf4X70fWwdsJUFgmGYfAe7m8wk\nLMy4CPTqJV/WGVQc7NJFJvyzU+9RW3lpJXb778a/o//NV4VPGIZhFNjdZCbDhkkh+CiHCnoFPw9G\nqz9a4cInF3K0pgHDMIwm7G7KJcLCjLubssLEIxPxdbuvWSAYhsnXsLvJTEJDM445mMuRe0fgG+GL\nrQO25syADMMwFoItCcja0oaIfBWJmd4z0zbSVcuBssVJqUn48vCXWNZrGUoULZH9ARmGYSxIoRcJ\nIqBePVmfWpcTD05gzpk58H8YCVtbw0WBMsvS80tR16Eu+tTtk/3BGIZhLEyhF4nQUODePbnHQRef\nMJkfaNeNwzkSj7jz7A5++vcnLOm5JPuDMQzD5AKFXiTOyTIKCAvTP+cT5oPhTYbjaPD+bMcjwl+G\no/eW3ljScwlq29fO3mAMwzC5RKEXCR8foFQpaVFokpCSgFtPb2HGWzNw5cURVHFMzvI9XiS8QO+t\nvTG21Vh81DSH1tAyDMPkAiwSPoCHh74lceXRFdQvXx8u9i6wTXGBqtq/hgfIgMSURLy//X28Vf0t\nTOk4JQdmzDAMk3sUapF4/VpmZX3vPX1LwifMB+0d2wMAKsR4ILzUfgMjmOZk0Em0W9MO5W3KY2mv\npRZLw80wDGMpCrVIXLkCNGgAuLrqWxI+YT5o7yRFougDD9xKMl8k7kbexbvb3sUnez/B9M7TsX3g\nds7LxDBMgaRQi4SPD9C+vdxJrWlJEBF8QtMtiZg7LZBALxAYFWhyvMhXkfji4BfotK4Tujh3gd84\nPwxsMJAtCIZhCiwWFwkhRC8hhL8QIkAIMdVIHzchxDUhxC0hxClLz0lBEYny5YFXr+QLAB6+eAgV\nqVDDrgZUKuDxoyLoU7cPDgQeMDhOqioVi88tRv1f6gMA/Mb5YVKHSShetHhufRSGYRiLYFGREEIU\nAbACQE8ADQEMFULU0+lTFsAvADyIqBGAQZackwJRukgIIXdTKy4nxdUkhMDTp4CtLdCvvgf2B+i7\nnIgIEw5PwJ9+f+LsqLNY3ns5ytuUz42PwDAMY3EsbUm0ARBIRCFElAzAC0A/nT4fAthFROEAQESR\nFp4TALnDmgioUUMeOzmlu5w0XU1KivDutbrjQvgFhL3UDl4sPLcQ3iHeODTsEOqV19I/hmGYAo+l\nRaIaAM11Q2HqNk3qArAXQpwSQlwSQuTKRgJNKwKQcQktS0ItEkpiv9LFSuO7Tt+h2W/NMPfMXLxO\nfo0tvluw4uIKHBp2CHYl7HJj2gzDMLlKfsgCWxRACwBdAZQC4COE8CGie7odZ86cmfbezc0Nbm5u\nWb6pIhIKiiXxOvk1bj+7jVZVWwHQThH+bedvMbjhYEw7MQ11V9RFUmoSTo44CUfbHMwhzjAMkw28\nvb3h7e2dY+NZWiTCAVTXOHZUt2kSBiCSiBIAJAghzgBoCsCkSGQXHx/A01NjYo6Ary9w5fEVNKjQ\nACWtZTY/3RThLvYu2DloJ3xCfVCiaAk0rNgwx+bEMAyTXXR/QM+aNStb41na3XQJQG0hhLMQohiA\nIQD26vTZA6CTEMJKCGEDoC0AP0tO6u6TENwovgKtWqW3KZbEudBzaa4mwHixofZO7dG8SnNLTpNh\nGCbPsahIEFEqgPEAjgK4DcCLiPyEEJ8JIcao+/gDOALAF8B5AH8Q0R1Lzmvgmi+R0nUyVFbxaW1K\nTOLI/SPoXqt7WntOFhtiGIYpaFg8JkFEhwG46rT9rnO8CMAiS88FAKavPwi/KD+0rNMKJ4NOoq9r\nXwBSCB5GvEBQ+CV0q9ktrX9Oly1lGIYpSBSqHdcnTidiwY2vsKznzxjarD/2BexLO+fgAMRXPor2\n1TqhVLFSAACVCnj0KGcq0jEMwxRE8sPqJotx5Qrw9Kl8HxcHjFq7GG17N8S4nr0QEFULi84tAhFB\nCAEhgBJN9qOdvUfa9U+fAmXLAiW4yijDMIWUN1YkUlOBLl2ATp3kXojXxR5CdFyMzcMvAwDqOtRF\n6WKlce3JNbSo0gKpqlQkOB2Eq5idNsaNGzL5H8MwTGHljXU3PXgAVKgAHDpE+HzpPjzq3h1T3/oa\nNcvVTOvjUTc91cbF8IsoRVWQ9Mw57fz+/UDv3rk+dYZhmHzDGysSvr6Ac9sb6L6pO6admIZlvZZh\neufpWn00RWJ/wH7Ut/JI23VNJEWib9/cnjnDMEz+4Y0Vicu+8bhQzx0D6w/Ejf/cwDt13tFL2d25\nemcERgfiSdwT7A/cjw4VPP6/vXuPkaq8wzj+fZab3LysFhRhwS4oi4iKKeK9aotQKTaGekPT1t5i\nar01pmJtbBr/qGm0Ma3V4i1EaQ1Iq2hNa9VQYqlFbQkoF9kF3ZW7LAgicvPXP87Z3WFlWMTZHc7M\n80kIM2fOHt7zMjvPvO973vc0r9+0aFESFCd6rpyZlbGSDYkXG55maK/RXPel6+hcsfehly6dujCm\negwPvv4gq7as4uxBpze3JJ57LrmtqW8FYWblrGRDYlHnaVw1fFKb+40fMp67/3U34waPY1BVp+aW\nRFNImJmVs8yHRG1jLeu3rt9j24p16/joyLl8/9zWq5J/2rgh49i+azvjjx/fPOt6w4ZkTONzrB9o\nZlYSMn8J7O0v3c6WHVt4/qrnm8cc7p89nSPeH8/hPXq1+fNH9TiKhyc8zMVDLqZHF9i2DWbOhPPP\n9/wIM7PMtyTqNtYxt2HuHrOn/1z7BCM7t93V1OTaU6+lZ9eeSMkSHA884K4mMzPIeEhEBLWNtTz0\n9Ye46W83sW3nNmoba1mzfQUXDf7qAR1zwACYP9/zI8zMIOPdTRu2baBCFVx24mVMf2s6v577awAq\nV13Oqecc2KkNGACnnQb9+hWypGZm2ZS5kIiAmhqYNw/qNtdRfUQ1APeMuYeRU0bSs0tPNr8yg5Pu\nOrDjn3wynHRSAQtsZpZhmQuJxkZYuhSWLIG67nVUVyYhMfDwgdw8+mYeeWMqhzSOom/fAzv+LbcU\nsLBmZhmXuZCor0/+XrwY6ge1tCQAJp89mepNP+DREZ4BZ2ZWCJkbuG4KiSVLkiubckOiU0Un6hf3\ncXeRmVmBZDIk+vTJCYnK6j1eX7AARowoUuHMzEpM5kKioQHGjElDorGOwZWD93h94UIPPJuZFUrm\nQqK+Hi64AJa/t5WNH2+kX++Wa1V37IBly2DYsCIW0MyshGRy4HrIEOhzwnK69TiOCrXk3NKlMGgQ\ndO9evPKZmZWSTIZEVRX0HVqH2HM84tVXk4lwZmZWGJkKiZ07Yf36ZDZ0r6o6dm7dMyTmzEnua21m\nZoWRqTGJVauSK5s6dwZV1rFr3adD4txzi1Q4M7MSlKmQaOpqAvioWx2blreExDvvwPbtcPzxxSmb\nmVkpylR3U25IrN9dx7o3q4lIbjHa1Irw7UbNzAonUy2JhoZkldZdn+xi5YcNdP94EGvWJK+5q8nM\nrPAyFRJNLYn6D+o5utfR1BzfjSVLktccEmZmhZfJkKhtrKX6iGqGDk0W+lu9Gt5/H4YPL3YJzcxK\nSyZDoq4xWdivpiZZnmPOHDjnHKjI1NmYmR38MvWx2jQmUbcxWbNp6NCWkHBXk5lZ4WUqJHbsgMrK\nltVfHRJmZu0rU5fAVlUll7g2dTdV9UnGIjZtglNPLXbpzMxKT6ZCYsAA2LZzGys2raC6sppOnZLJ\nc337JrOwzcyssDL10VpVBc++/Syj+4/m0G6HAlBT4/tHmJm1l8yFxLSF05h00qTmbffeC717F7FQ\nZmYlLFMD15XHNjL7ndlcWnNp87ZjjoFevYpYKDOzEpapkKjrNoOLqi9q7moyM7P2lamQeGXzNK4e\ncXWxi2FmVjYyFRIrPlzE2MFji10MM7Oy0e4hIWmspCWS3pb00728fp6kTZL+m/65I9+xJg6bSNdO\nXdu3wGZm1qxdQ0JSBfA74CLgROBKSUP3suuciBiZ/rkr3/Fyr2oqZ7Nnzy52EQ4arosWrosWrovC\nae+WxChgWUS8GxE7gSeBS/ay337dKuisqrMKWbbM8i9AC9dFC9dFC9dF4bR3SBwLNOQ8fy/d1toZ\nkuZL+qukYfkOVqFMDaGYmWXewTCZ7g2gKiI+kjQOeBrwnarNzA4Cioj2O7g0GvhFRIxNn98GRETc\nvY+fWQGcFhGNrba3X0HNzEpYROxXl/7etHdL4jVgsKSBwGrgCuDK3B0k9Y2ItenjUSTB1dj6QJ/n\nJM3M7MC0a0hExG5J1wMvkIx/PBIRiyX9MHk5pgATJV0H7AS2AZe3Z5nMzGz/tWt3k5mZZVsmLhdq\na0JeKZPUX9LLkt6StFDSDen2IyS9IGmppL9LOqzYZe0IkirSSZez0uflWg+HSZohaXH63ji9jOvi\nZklvSlogaZqkruVUF5IekbRW0oKcbXnPX9JkScvS986Yto5/0IfEZ5iQV6p2AbdExInAGcCP0vO/\nDXgxIk4AXgYmF7GMHelGYFHO83Kth/uA5yOiBjgZWEIZ1oWkfsCPgZERMYKkC/1KyqsuHiP5fMy1\n1/NPpxhcBtQA44DfS9rneO9BHxLs/4S8khQRayJifvr4Q2Ax0J+kDqamu00FvlGcEnYcSf2BrwEP\n52wux3o4FDgnIh4DiIhdEfEBZVgXqU5AT0mdge7ASsqoLiLiFWBjq835zn8C8GT6nnkHWEbyGZtX\nFkJifyfklTxJg4BTgFeB5qvCImIN0Kd4JeswvwFuBXIH0sqxHo4D3pf0WNr1NkVSD8qwLiJiFXAP\nUE8SDh9ExIuUYV200ifP+bf+PF1JG5+nWQgJAyT1Ap4CbkxbFK2vOCjpKxAkXQysTVtV+2oel3Q9\npDoDI4H7I2IksJWke6Gs3hMAkg4n+dY8EOhH0qKYRBnWRRsO+PyzEBIrgaqc5/3TbWUjbUY/BTwe\nEc+km9dK6pu+fjSwrljl6yBnARMkLQf+BFwg6XFgTZnVAySt6YaIeD19PpMkNMrtPQHwFWB5RDRG\nxG7gL8CZlGdd5Mp3/iuBATn7tfl5moWQaJ6QJ6kryYS8WUUuU0d7FFgUEfflbJsFfDt9/C3gmdY/\nVEoi4vaIqIqIL5K8B16OiGuAZymjegBIuxEaJDUtX3Mh8BZl9p5I1QOjJR2SDsBeSHJhQ7nVhdiz\nhZ3v/GcBV6RXgB0HDAbm7fPAWZgnIWksydUcTRPyflXkInUYSWcBc4CFJE3GAG4n+Y+dTvKt4F3g\nsojYVKxydiRJ5wE/iYgJkiopw3qQdDLJAH4XYDnwHZIB3HKsiztJvjjsBP4HfA/oTZnUhaQ/Al8G\njgTWAneSrIE3g72cv6TJwHdJ6uvGiHhhn8fPQkiYmVlxZKG7yczMisQhYWZmeTkkzMwsL4eEmZnl\n5ZAwM7O8HBJmZpaXQ8KsA0g6T9KzxS6H2WflkDDrOJ6UZJnjkDDLIWmSpP+kq6s+kN7kaIuke9Mb\n2/xD0pHpvqdI+rek+ZJmNt3YRVJ1ut98Sa+nyx8A9M65UdDjRTtJs8/AIWGWSm/mdDlwZrq66ifA\nJKAHMC8ihpMskXJn+iNTgVsj4hTgzZzt04DfptvPBFan208BbgCGAdWSzmz/szL7fDoXuwBmB5EL\nSVZTfS1dLO4QkrVwPiFZBwjgCWBmeuOfw9IbvkASGNPTJd2PjYhZABGxAyC9+de8iFidPp8PDALm\ndsB5mR0wh4RZCwFTI+Jne2yUft5qv8jZ/7PYnvN4N/79swxwd5NZi5eAiZK+AM03k68iWV11YrrP\nJOCViNgMNKar9AJcA/wzvSFUg6RL0mN0ldS9Q8/CrID8TcYsFRGLJd0BvCCpAtgBXE9y57dRaYti\nLcm4BSTr9P8hDYGm5bohCYwpkn6ZHuObe/vn2u9MzArHS4WbtUHSlojoXexymBWDu5vM2uZvUla2\n3JIwM7O83JIwM7O8HBJmZpaXQ8LMzPJySJiZWV4OCTMzy8shYWZmef0fAZaPjvBFOZ8AAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17a8144d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
